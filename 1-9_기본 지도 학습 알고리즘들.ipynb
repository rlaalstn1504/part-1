{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "851b6401",
      "metadata": {},
      "source": [
        "#  ê¸°ë³¸ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ë“¤\n",
        "\n",
        "### ê¸°íš ë°°ê²½\n",
        "- **ê¸°ë³¸ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ë“¤**ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•µì‹¬ì¸ **ì§€ë„ í•™ìŠµ(Supervised Learning)** ì„ ë°°ìš°ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.  \n",
        "- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ê¸°ë¥¼ ë‹¤ì§„ í›„, ì‹¤ì œ ë°ì´í„°ì— ì ìš©í•  ìˆ˜ ìˆëŠ” **íšŒê·€ì™€ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜**ì„ ìµí˜€ì•¼ í•©ë‹ˆë‹¤.  \n",
        "- ë‹¨ìˆœí•˜ê³  ì§ê´€ì ì¸ ì•Œê³ ë¦¬ì¦˜ì„ ë¨¼ì € ë°°ìš°ë©´, ì´í›„ ë³µì¡í•œ ëª¨ë¸(ë”¥ëŸ¬ë‹ í¬í•¨)ì—ë„ ê°™ì€ ì›ë¦¬ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "\n",
        "\n",
        "### í•™ìŠµ ëª©í‘œ\n",
        "ì´ í† í”½ì„ ìˆ˜ê°•í•œ ë’¤, ìˆ˜ê°•ìƒì€ ë‹¤ìŒì„ í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "- ì§€ë„ í•™ìŠµì˜ ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜ì¸ **ì„ í˜• íšŒê·€, ë‹¤ì¤‘ ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€**ì˜ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤.  \n",
        "- ì†ì‹¤ í•¨ìˆ˜ì™€ ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.  \n",
        "- `scikit-learn` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ì‹¤ì œ ë°ì´í„°ë¥¼ í•™ìŠµ/ì˜ˆì¸¡/í‰ê°€í•  ìˆ˜ ìˆë‹¤.  \n",
        "- ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆë‹¤.  \n",
        "\n",
        "\n",
        "## ëª©ì°¨\n",
        "\n",
        "### 0. ë“¤ì–´ê°€ê¸°\n",
        "- ì§€ë„ í•™ìŠµ(Supervised Learning)ì˜ ê°œë… ë³µìŠµ  \n",
        "- íšŒê·€(Regression)ì™€ ë¶„ë¥˜(Classification)ì˜ ì°¨ì´"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6256f6",
      "metadata": {},
      "source": [
        "### 1. ì„ í˜• íšŒê·€ (Linear Regression)\n",
        "- ê°œë…: ì…ë ¥(x)ê³¼ ì¶œë ¥(y)ì˜ **ì§ì„ ì  ê´€ê³„**ë¥¼ ëª¨ë¸ë§  \n",
        "- ìˆ˜í•™ì  í‘œí˜„:  \n",
        "  $y = w x + b$\n",
        "- ì†ì‹¤ í•¨ìˆ˜: í‰ê· ì œê³±ì˜¤ì°¨(MSE)  \n",
        "- ê²½ì‚¬ í•˜ê°•ë²• ê°œë… & í•™ìŠµë¥ ì˜ ì—­í•   \n",
        "- Numpyë¡œ ì§ì ‘ êµ¬í˜„í•˜ê¸°  \n",
        "- `scikit-learn` ì˜ˆì œ: ë‹¨ìˆœ ì„ í˜• íšŒê·€\n",
        "\n",
        "\n",
        "<img src=\"image/linear_regression.png\" width=\"500\">  \n",
        "\n",
        "ì´ë¯¸ì§€ ì¶œì²˜ : [https://www.lennysnewsletter.com/p/linear-regression-and-correlation-analysis](https://www.lennysnewsletter.com/p/linear-regression-and-correlation-analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29d523c",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### 2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ (Multiple Linear Regression)\n",
        "- ê°œë…: ì…ë ¥ ë³€ìˆ˜ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°  \n",
        "- ìˆ˜í•™ì  í‘œí˜„:  \n",
        "  $\n",
        "  y = w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n + b\n",
        "  $\n",
        "- ê²½ì‚¬ í•˜ê°•ë²• ì ìš©  \n",
        "- ì •ê·œë°©ì •ì‹(Closed-form solution)  \n",
        "- ê²½ì‚¬ í•˜ê°•ë²• vs ì •ê·œë°©ì •ì‹ ë¹„êµ  \n",
        "- `scikit-learn` ì˜ˆì œ: ë‹¤ì¤‘ ì„ í˜• íšŒê·€  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a225da2",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### 3. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\n",
        "- ê°œë…: **ë¶„ë¥˜(Classification)** ë¬¸ì œì— ì‚¬ìš©  \n",
        "- ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜:  \n",
        "  $\n",
        "  \\sigma(z) = \\frac{1}{1+e^{-z}}\n",
        "  $\n",
        "- ê²°ì • ê²½ê³„ì™€ í™•ë¥ ì  í•´ì„  \n",
        "- ì†ì‹¤ í•¨ìˆ˜: ë¡œì§€ìŠ¤í‹± ì†ì‹¤(Log loss)  \n",
        "- Numpyë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ êµ¬í˜„  \n",
        "- `scikit-learn` ì˜ˆì œ: ì´ì§„ ë¶„ë¥˜, ë‹¤ì¤‘ ë¶„ë¥˜  \n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì§€ë„ í•™ìŠµ = ì…ë ¥ê³¼ ì •ë‹µ(Label)ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ì‹  \n",
        "- íšŒê·€(ì—°ì†ê°’ ì˜ˆì¸¡) vs ë¶„ë¥˜(ë²”ì£¼ ì˜ˆì¸¡) êµ¬ë¶„ ê°€ëŠ¥  \n",
        "- ì„ í˜• íšŒê·€ â†’ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ â†’ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì§€ë„ í•™ìŠµì˜ ê¸°ë³¸ê¸°  \n",
        "- ì†ì‹¤ í•¨ìˆ˜ì™€ ê²½ì‚¬ í•˜ê°•ë²•ì€ ëª¨ë“  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì˜ í•µì‹¬ ê°œë…  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03eb2050",
      "metadata": {},
      "source": [
        "## 0. ë“¤ì–´ê°€ê¸°\n",
        "\n",
        "ì§€ë„ í•™ìŠµ(Supervised Learning)ì€ **ì…ë ¥(x)** ê³¼ **ì •ë‹µ(y)** ì„ í•¨ê»˜ ì œê³µí•˜ì—¬,  \n",
        "ëª¨ë¸ì´ xâ†’y ê·œì¹™ì„ í•™ìŠµí•˜ê²Œ ë§Œë“œëŠ” ë°©ì‹ì…ë‹ˆë‹¤.  \n",
        "\n",
        "- **íšŒê·€(Regression)**: ì—°ì†ì ì¸ ìˆ«ìë¥¼ ì˜ˆì¸¡ (ì˜ˆ: ì§‘ê°’, í‚¤, ëª¸ë¬´ê²Œ)  \n",
        "- **ë¶„ë¥˜(Classification)**: ë²”ì£¼ë¥¼ ì˜ˆì¸¡ (ì˜ˆ: ìŠ¤íŒ¸/í–„, í•©ê²©/ë¶ˆí•©ê²©)  \n",
        "\n",
        "ğŸ‘‰ ì´ë²ˆ íŒŒíŠ¸ì—ì„œëŠ” ê°€ì¥ ê¸°ì´ˆì ì¸ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì¸ **ì„ í˜• íšŒê·€(Linear Regression)** ë¥¼ ë°°ì›ë‹ˆë‹¤.  \n",
        "\n",
        "> ë¹„ìœ : **íšŒê·€ëŠ” ì£¼ê´€ì‹(ì—°ì† ê°’ ë²”ìœ„ì—ì„œ ë‹µ)**, **ë¶„ë¥˜ëŠ” ê°ê´€ì‹(ë¼ë²¨ ì¤‘ í•˜ë‚˜ ì„ íƒ)**.  \n",
        "> ë‘ ê³¼ì—…ì€ **ë³¸ì§ˆì´ ë‹¤ë¥´ë¯€ë¡œ ì†ì‹¤í•¨ìˆ˜ì™€ í‰ê°€ì§€í‘œê°€ ë‹¤ë¦…ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c58092",
      "metadata": {},
      "source": [
        "### 0.1 íšŒê·€ vs ë¶„ë¥˜: ì™œ ì†ì‹¤ í•¨ìˆ˜Â·í‰ê°€ ì§€í‘œê°€ ë‹¤ë¥¸ê°€?\n",
        "- **íšŒê·€**ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ **ìˆ˜ì¹˜ì  ê±°ë¦¬**ë¥¼ ì¤„ì´ëŠ” ë¬¸ì œê°€ í•µì‹¬ â†’ â€œì˜¤ì°¨ì˜ í¬ê¸°â€ë¥¼ ì§ì ‘ ìµœì†Œí™”í•˜ëŠ” ì†ì‹¤ì´ í•„ìš”.  \n",
        "- **ë¶„ë¥˜**ëŠ” **í™•ë¥ ì  ì˜ì‚¬ê²°ì •**(ì •ë‹µ ë¼ë²¨ì— ë†’ì€ í™•ë¥ ì„ ë¶€ì—¬)ê³¼ **ì˜ì‚¬ê²°ì • ì„ê³„ê°’**ì´ í•µì‹¬ â†’ í™•ë¥ ë¶„í¬ì™€ ë¶„ë¦¬ë„ë¥¼ ë°˜ì˜í•˜ëŠ” ì†ì‹¤Â·ì§€í‘œê°€ í•„ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a37650",
      "metadata": {},
      "source": [
        "### 0.2 ì†ì‹¤í•¨ìˆ˜(íšŒê·€)\n",
        "- **MSE(Mean Squared Error)**: $(\\frac{1}{N}\\sum (y-\\hat y)^2$)  \n",
        "  - í° ì˜¤ì°¨ì— ê°€ì¤‘(ì œê³±) â†’ ì´ìƒì¹˜ì— ë¯¼ê°, í‰ê· ì ìœ¼ë¡œ ë§¤ëˆí•˜ê²Œ ë§ì¶¤.\n",
        "- **MAE(Mean Absolute Error)**: $(\\frac{1}{N}\\sum |y-\\hat y|$)  \n",
        "  - ì´ìƒì¹˜ì— ëœ ë¯¼ê°, ì¤‘ì•™ê°’ ì í•©ì— ê°€ê¹Œì›€.\n",
        "- **Huber/Smooth L1**: ì‘ì€ ì˜¤ì°¨ëŠ” ì œê³±, í° ì˜¤ì°¨ëŠ” ì ˆëŒ€ê°’ â†’ **MSEÂ·MAE ì ˆì¶©**(ì´ìƒì¹˜ ì™„í™”).\n",
        "- **Quantile Loss**: íŠ¹ì • ë¶„ìœ„ìˆ˜(ì˜ˆ: P90) ì˜ˆì¸¡ â†’ **ìˆ˜ìš”ì˜ˆì¸¡, ë¦¬ìŠ¤í¬ ìƒí•œ/í•˜í•œ ì¶”ì •**ì— ìœ ìš©.\n",
        "\n",
        "    <img src=\"image/linear regression-error.png\" width=\"500\">  \n",
        "\n",
        "    ì´ë¯¸ì§€ ì¶œì²˜ : [https://community.cloudera.com/t5/Community-Articles/Understanding-Linear-Regression/ta-p/281391](https://community.cloudera.com/t5/Community-Articles/Understanding-Linear-Regression/ta-p/281391)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359c5d98",
      "metadata": {},
      "source": [
        "### 0.3 ì†ì‹¤í•¨ìˆ˜(ë¶„ë¥˜)\n",
        "- **Binary Cross-Entropy(Log Loss)**: ì´ì§„ ë¶„ë¥˜  \n",
        "  - ì •ë‹µ ë¼ë²¨ì— í™•ë¥ ì„ ìµœëŒ€í™”(ì˜ëª» í™•ì‹ í•˜ë©´ í° íŒ¨ë„í‹°).\n",
        "- **Categorical Cross-Entropy**: ë‹¤ì¤‘ ë¶„ë¥˜(softmax)  \n",
        "  - ì •ë‹µ í´ë˜ìŠ¤ í™•ë¥ ì„ í‚¤ìš°ê³ , ì˜¤ë‹µ í™•ë¥ ì„ ë‚®ì¶¤.\n",
        "\n",
        "    <img src=\"image/softmax.webp\" width=\"500\">  \n",
        "\n",
        "    ì´ë¯¸ì§€ ì¶œì²˜ : [https://www.singlestore.com/blog/a-guide-to-softmax-activation-function/](https://www.singlestore.com/blog/a-guide-to-softmax-activation-function/)\n",
        "    softmax.webp\n",
        "\n",
        "- **Focal Loss**: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” í° ê°€ì¤‘ â†’ **ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ê°•í™”**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f6f8cd",
      "metadata": {},
      "source": [
        "### 0.4 í‰ê°€ì§€í‘œ(íšŒê·€)\n",
        "- **RMSE**: $\\sqrt{\\text{MSE}}$, ë‹¨ìœ„ê°€ ì›ë˜ íƒ€ê¹ƒê³¼ ê°™ì•„ í•´ì„ ìš©ì´.  \n",
        "- **MAE**: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨, ì´ìƒì¹˜ ê°•ê±´ì„±.  \n",
        "- **MAPE**: í‰ê·  ìƒëŒ€ ì˜¤ì°¨(%) â€” **0 ê·¼ì²˜ íƒ€ê¹ƒ, ìŒìˆ˜, ë‹¨ìœ„ ë¬¸ì œì— ì£¼ì˜**.  \n",
        "- **\\(R^2\\)**: ì„¤ëª…ë ¥(0~1 ì´ìƒ), ê¸°ì¤€ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ â€” **ë¶ˆê· í˜• ë²”ìœ„Â·ë¹„ì„ í˜•ì¼ ë•Œ ì˜¤í•´ ì†Œì§€**.\n",
        "\n",
        "### 0.5 í‰ê°€ì§€í‘œ(ë¶„ë¥˜)\n",
        "- **Accuracy**: ì „ì²´ ì •ë‹µ ë¹„ìœ¨ â€” **í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ì·¨ì•½**.  \n",
        "- **Precision / Recall / F1**:  \n",
        "  - Precision: ì˜ˆì¸¡í•œ ì–‘ì„± ì¤‘ ì§„ì§œ ì–‘ì„± ë¹„ìœ¨  \n",
        "  - Recall: ì‹¤ì œ ì–‘ì„± ì¤‘ ì¡ì•„ë‚¸ ë¹„ìœ¨  \n",
        "  - F1: ì •ë°€Â·ì¬í˜„ ì¡°í™” í‰ê· (ì„ê³„ê°’ ë¯¼ê°)  \n",
        "  - **ë§ˆì´í¬ë¡œ/ë§¤í¬ë¡œ í‰ê· ** ì„ íƒì— ìœ ì˜(ë‹¤ì¤‘ í´ë˜ìŠ¤/ë¶ˆê· í˜•).\n",
        "- **ROC-AUC**: ì„ê³„ê°’ ì „ ë²”ìœ„ì—ì„œ ë¶„ë¦¬ë„(íŠ¹ì´ë„ vs ë¯¼ê°ë„).  \n",
        "- **PR-AUC**: ì–‘ì„± í¬ì†Œ ì‹œ **ë” ì •ë³´ëŸ‰ ìˆëŠ” ì§€í‘œ**.  \n",
        "- **Log Loss**: í™•ë¥  ë³´ì •(calibration)ê¹Œì§€ í‰ê°€.\n",
        "\n",
        "\n",
        "### 0.6 ì„ íƒ ê°€ì´ë“œ(ì‹¤ì „)\n",
        "- **íšŒê·€**\n",
        "  - ì´ìƒì¹˜ ë§ìŒ â†’ **Huber/MAE**, ì§€í‘œëŠ” **MAE + RMSE** ë³‘í–‰, **RÂ²** ì°¸ê³ .\n",
        "  - ìƒëŒ€ì˜¤ì°¨ ì¤‘ìš”(%) â†’ **MAPE**(ë‹¨, 0/ìŒìˆ˜ ì²˜ë¦¬ ì„¤ê³„ í•„ìˆ˜).\n",
        "- **ë¶„ë¥˜**\n",
        "  - **ë¶ˆê· í˜•** ì‹¬í•¨ â†’ ì†ì‹¤ì€ **Focal/ê°€ì¤‘ CE**, ì§€í‘œëŠ” **PR-AUC + F1** ì¶”ì²œ.  \n",
        "  - **í™•ë¥  ë³´ì •** í•„ìš” â†’ **Log Loss** ëª¨ë‹ˆí„°ë§ ë° calibration(Platt/Isotonic) ê³ ë ¤.\n",
        "  - **ìš´ì˜ ì„ê³„ê°’** ê²°ì • â†’ ROC/PR ê³¡ì„  ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™”(ì½”ìŠ¤íŠ¸, ì¬í˜„ìœ¨ ëª©í‘œ ë“±).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 0.7-1 ì†ì‹¤í•¨ìˆ˜ ìš”ì•½ í‘œ\n",
        "\n",
        "| ê³¼ì—… | ëŒ€í‘œ ì†ì‹¤í•¨ìˆ˜ | í•µì‹¬ íŠ¹ì§• | ë¹„ê³ /ì£¼ì˜ |\n",
        "|---|---|---|---|\n",
        "| **íšŒê·€** | **MSE** | ì˜¤ì°¨ ì œê³± í‰ê· . í° ì˜¤ì°¨ì— ë” í° íŒ¨ë„í‹° â†’ ë§¤ëˆí•œ ì í•© | ì´ìƒì¹˜ì— ë¯¼ê° |\n",
        "|  | **MAE** | ì ˆëŒ€ì˜¤ì°¨ í‰ê· . ì´ìƒì¹˜ì— ê°•ê±´ | ë¯¸ë¶„ ë¶ˆì—°ì†(0 ê·¼ì²˜) â€“ êµ¬í˜„ì€ ê°€ëŠ¥ |\n",
        "|  | **Huber / Smooth L1** | ì‘ì€ ì˜¤ì°¨ëŠ” ì œê³±, í° ì˜¤ì°¨ëŠ” ì ˆëŒ€ê°’ â†’ MSEÂ·MAE ì ˆì¶© | ì´ìƒì¹˜ ì™„í™” + ì•ˆì •ì  í•™ìŠµ |\n",
        "|  | **Quantile Loss** | ë¶„ìœ„ìˆ˜(ì˜ˆ: P90) ì˜ˆì¸¡ | ìˆ˜ìš”/ë¦¬ìŠ¤í¬ ìƒí•˜í•œ ì˜ˆì¸¡ì— ìœ ìš© |\n",
        "| **ë¶„ë¥˜(ì´ì§„)** | **Binary Cross-Entropy (Log Loss)** | ì •ë‹µ ë¼ë²¨ í™•ë¥  ìµœëŒ€í™”(ì˜ëª»ëœ í™•ì‹ ì— í° íŒ¨ë„í‹°) | ì‹œê·¸ëª¨ì´ë“œ/ë¡œì§€ìŠ¤í‹±ê³¼ í•¨ê»˜ ì‚¬ìš© |\n",
        "| **ë¶„ë¥˜(ë‹¤ì¤‘)** | **Categorical Cross-Entropy** | ì •ë‹µ í´ë˜ìŠ¤ í™•ë¥  ìµœëŒ€í™” | ì†Œí”„íŠ¸ë§¥ìŠ¤ì™€ í•¨ê»˜ ì‚¬ìš© |\n",
        "| **ë¶ˆê· í˜•/ë‚œìƒ˜í”Œ ê°€ì¤‘** | **Focal Loss** | ì–´ë ¤ìš´ ìƒ˜í”Œì— ê°€ì¤‘, ì‰¬ìš´ ìƒ˜í”Œ í˜ë„í‹° ê°ì†Œ | í´ë˜ìŠ¤ ë¶ˆê· í˜• ì™„í™” |\n",
        "\n",
        "> ë©”ëª¨: í™•ë¥  ë³´ì •(calibration)ì€ ë³„ë„ ì£¼ì œì´ë©°, ì†ì‹¤í•¨ìˆ˜ ìì²´ë³´ë‹¤ëŠ” **ì¶”ì • í™•ë¥ ì˜ í’ˆì§ˆ**(ì˜ˆ: Log Loss, Brier)ì— ë” ê´€ë ¨ë©ë‹ˆë‹¤. ì´ ì¥ì—ì„œëŠ” ë¶„ë¥˜ ì§€í‘œë¥¼ ë‹¨ìˆœí™”(Accuracy/Precision/Recall/F1)í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "#### 0.7-2 í‰ê°€ì§€í‘œ ìš”ì•½ í‘œ\n",
        "\n",
        "| ê³¼ì—… | ëŒ€í‘œ í‰ê°€ì§€í‘œ | ì •ì˜(ìš”ì•½) | ë¹„ê³ /ì£¼ì˜ |\n",
        "|---|---|---|---|\n",
        "| **íšŒê·€** | **RMSE** | MSEì˜ ì œê³±ê·¼(íƒ€ê¹ƒ ë‹¨ìœ„ì™€ ë™ì¼) | í° ì˜¤ì°¨ì— ë¯¼ê° |\n",
        "|  | **MAE** | ì ˆëŒ€ì˜¤ì°¨ í‰ê·  | ì´ìƒì¹˜ ê°•ê±´ |\n",
        "|  | **MAPE** | ìƒëŒ€ì˜¤ì°¨ í‰ê· (%) | 0/ìŒìˆ˜ ì·¨ê¸‰ ì£¼ì˜, ìŠ¤ì¼€ì¼ ì˜í–¥ ì ìŒ |\n",
        "|  | **RÂ²** | ì„¤ëª…ë ¥(ê¸°ì¤€ëª¨ë¸ ëŒ€ë¹„ ê°œì„  ë¹„ìœ¨) | ë¹„ì„ í˜•/ë¶„ì‚° í° ë°ì´í„°ì—ì„œ ì˜¤í•´ ì†Œì§€ |\n",
        "| **ë¶„ë¥˜** | **Accuracy** | (TP+TN)/ì „ì²´ | ë¶ˆê· í˜• ì‹œ ì™œê³¡ ìœ„í—˜ í¼ |\n",
        "|  | **Precision** | TP/(TP+FP) | ì–‘ì„± ì˜ˆì¸¡ì˜ â€œì •í™•í•¨â€ |\n",
        "|  | **Recall** | TP/(TP+FN) | ì‹¤ì œ ì–‘ì„± í¬ì°©ë¥ (ë¯¼ê°ë„) |\n",
        "|  | **F1-score** | 2Â·(PÂ·R)/(P+R) | Precisionâ€“Recall ê· í˜• ì§€í‘œ |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4536d006",
      "metadata": {},
      "source": [
        "#### í˜¼ë™í–‰ë ¬(Confusion Matrix) í‘œ\n",
        "\n",
        "| ì‹¤ì œ \\ ì˜ˆì¸¡ | 0 (Negative)         | 1 (Positive)         |\n",
        "|-------------|-----------------------|-----------------------|\n",
        "| **0 (Negative)** | **TN**: ì§„ì§œ ìŒì„± (ì •ìƒ ì •ë‹µ) | **FP**: ê±°ì§“ ì–‘ì„± (ê±°ì§“ ê²½ë³´) |\n",
        "| **1 (Positive)** | **FN**: ê±°ì§“ ìŒì„± (ë†“ì¹¨)     | **TP**: ì§„ì§œ ì–‘ì„± (ì •ìƒ ê²€ì¶œ) |\n",
        "\n",
        "#### í˜¼ë™í–‰ë ¬(Confusion Matrix) ìš©ì–´ ì •ë¦¬\n",
        "- **TP (True Positive)**: ì‹¤ì œ 1ì´ê³ , ì˜ˆì¸¡ë„ 1  \n",
        "- **FP (False Positive)**: ì‹¤ì œ 0ì¸ë°, ì˜ˆì¸¡ì´ 1 (ê±°ì§“ ê²½ë³´)  \n",
        "- **TN (True Negative)**: ì‹¤ì œ 0ì´ê³ , ì˜ˆì¸¡ë„ 0  \n",
        "- **FN (False Negative)**: ì‹¤ì œ 1ì¸ë°, ì˜ˆì¸¡ì´ 0 (ë†“ì¹¨)\n",
        "\n",
        "#### **ì§€í‘œ ê³µì‹**  \n",
        " - Accuracy = (TP + TN) / (TP + FP + TN + FN)  \n",
        " - Precision = TP / (TP + FP)  \n",
        " - Recall = TP / (TP + FN)  \n",
        " - F1 = 2 Â· (Precision Â· Recall) / (Precision + Recall)\n",
        "\n",
        "\n",
        "\n",
        "#### ì™œ Accuracyë§Œ ë³´ë©´ ìœ„í—˜í•œê°€? (ì™œê³¡ ì‚¬ë¡€)\n",
        "\n",
        "- **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: ì–‘ì„±ì´ 1%ì¸ ë°ì´í„°ì—ì„œ ì „ë¶€ 0ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ **ì •í™•ë„ 99%**ì§€ë§Œ,  \n",
        "  - Recall = 0 (ì–‘ì„± ì „ë¶€ ë†“ì¹¨), Precision ì •ì˜ ë¶ˆê°€(ì–‘ì„± ì˜ˆì¸¡ ì—†ìŒ) â†’ **ì‹¤ì „ ì„±ëŠ¥ í˜•í¸ì—†ìŒ**\n",
        "- **ì„ê³„ê°’(Threshold) ë¯¼ê°ì„±**: ê°™ì€ ëª¨ë¸ë„ ì„ê³„ê°’ ì„ íƒì— ë”°ë¼ AccuracyëŠ” ë¹„ìŠ·í•´ ë³´ì—¬ë„ **Precision/Recall íŠ¸ë ˆì´ë“œì˜¤í”„**ê°€ í¬ê²Œ ë‹¬ë¼ì§\n",
        "- **ë¹„ëŒ€ì¹­ ë¹„ìš©**: FPì™€ FNì˜ ë¹„ìš©ì´ ë‹¤ë¥´ë©´ Accuracyë§Œ ë†’ì—¬ë„ **ìš´ì˜ ë¹„ìš©**ì´ ì»¤ì§ˆ ìˆ˜ ìˆìŒ  \n",
        "  (ì˜ˆ: ë¶ˆëŸ‰ ê²€ì¶œì—ì„œ FNì€ ì¹˜ëª…ì  ì†ì‹¤)\n",
        "\n",
        "> ì‹¤ì „ ê¶Œì¥: **Accuracy + (Precision/Recall/F1)** ë¥¼ í•¨ê»˜ ë³´ê³ , ì—…ë¬´ ë¹„ìš©/ëª©í‘œì— ë§ì¶° **ì„ê³„ê°’ì„ ìµœì í™”**í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e368d4",
      "metadata": {},
      "source": [
        "### ì—°ìŠµ ë¬¸ì œ) ì•” ì§„ë‹¨ ëª¨ë¸ í‰ê°€\n",
        "\n",
        "í•œ ë³‘ì›ì—ì„œ **ì•”(ì–‘ì„±, Positive)** / **ì •ìƒ(ìŒì„±, Negative)** ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.  \n",
        "í…ŒìŠ¤íŠ¸ ë°ì´í„° 100ëª…ì— ëŒ€í•œ ì‹¤ì œê°’ê³¼ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "|              | ì‹¤ì œ ì•” (Positive) | ì‹¤ì œ ì •ìƒ (Negative) |\n",
        "|--------------|--------------------|-----------------------|\n",
        "| **ì˜ˆì¸¡ ì•”**      | 5                  | 5                     |\n",
        "| **ì˜ˆì¸¡ ì •ìƒ**    | 5                  | 85                    |\n",
        "\n",
        "\n",
        "ìœ„ í‘œëŠ” **í˜¼ë™í–‰ë ¬(Confusion Matrix)** ì…ë‹ˆë‹¤.  \n",
        "- TP (ì°¸ì–‘ì„±) = 5  \n",
        "- FP (ê±°ì§“ì–‘ì„±) = 5  \n",
        "- FN (ê±°ì§“ìŒì„±) = 5  \n",
        "- TN (ì°¸ìŒì„±) = 85  \n",
        "\n",
        "\n",
        "#### ë¬¸ì œ\n",
        "1. Accuracy, Precision, Recall, F1 Scoreë¥¼ ê°ê° ê³„ì‚°í•˜ì‹œì˜¤.  \n",
        "2. ì™œ Accuracyë§Œ ë³´ë©´ ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ì•„ ë³´ì¼ ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•˜ì‹œì˜¤.  \n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ</summary>\n",
        "\n",
        "```python\n",
        "TP, FP, FN, TN = 5, 5, 5, 85\n",
        "\n",
        "# 1. Accuracy\n",
        "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
        "# (5 + 85) / 100 = 0.90\n",
        "\n",
        "# 2. Precision (ì–‘ì„± ì˜ˆì¸¡ì˜ ì •í™•ë„)\n",
        "precision = TP / (TP + FP)\n",
        "# 5 / (5 + 5) = 0.50\n",
        "\n",
        "# 3. Recall (ì–‘ì„± ì¤‘ ë†“ì¹˜ì§€ ì•Šì€ ë¹„ìœ¨)\n",
        "recall = TP / (TP + FN)\n",
        "# 5 / (5 + 5) = 0.50\n",
        "\n",
        "# 4. F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "# 2 * (0.5 * 0.5) / (0.5 + 0.5) = 0.50\n",
        "\n",
        "print(f\"Accuracy={accuracy:.2f}, Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")\n",
        "```\n",
        "\n",
        "ì¶œë ¥:\n",
        "```\n",
        "Accuracy=0.90, Precision=0.50, Recall=0.50, F1=0.50\n",
        "```\n",
        "\n",
        "#### í•´ì„¤\n",
        "- Accuracyë§Œ ë³´ë©´ **90%**ë¡œ ì„±ëŠ¥ì´ ì¢‹ì•„ ë³´ì„.  \n",
        "- í•˜ì§€ë§Œ ì‹¤ì œ ì•” í™˜ì(ì–‘ì„±)ëŠ” ì ˆë°˜ì´ë‚˜ ë†“ì³¤ìŒ(Recall=0.5).  \n",
        "- Precisionë„ 0.5 â†’ ì•”ì´ë¼ê³  ì˜ˆì¸¡í•œ ì ˆë°˜ì€ ì •ìƒì¸ ì‚¬ëŒ.  \n",
        "- **ê²°ë¡ **: í´ë˜ìŠ¤ ë¶ˆê· í˜•(ì•”=10ëª…, ì •ìƒ=90ëª…) ìƒí™©ì—ì„œ AccuracyëŠ” ê³¼ëŒ€í‰ê°€ë¥¼ ì¼ìœ¼í‚´.  \n",
        "  â†’ ì´ëŸ° ê²½ìš° **Precision, Recall, F1** ì§€í‘œë¡œ ì„±ëŠ¥ì„ ë°˜ë“œì‹œ í•¨ê»˜ í‰ê°€í•´ì•¼ í•¨.  \n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b47760",
      "metadata": {},
      "source": [
        "## 1. ì„ í˜• íšŒê·€ (Linear Regression)\n",
        "\n",
        "<img src=\"image/linear_regression.png\" width=\"500\">  \n",
        "\n",
        "ì´ë¯¸ì§€ ì¶œì²˜ : [https://www.lennysnewsletter.com/p/linear-regression-and-correlation-analysis](https://www.lennysnewsletter.com/p/linear-regression-and-correlation-analysis)\n",
        "\n",
        "### 1.1 ê°œë…\n",
        "- ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ **ì§ì„ (Linear)** ìœ¼ë¡œ ëª¨ë¸ë§  \n",
        "- ë‹¨ìˆœ ì„ í˜• íšŒê·€:  \n",
        "  $$\n",
        "  y = w x + b\n",
        "  $$  \n",
        "  - w = ê¸°ìš¸ê¸°(ê°€ì¤‘ì¹˜, weight)  \n",
        "  - b = ì ˆí¸(bias)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1ef1ca",
      "metadata": {},
      "source": [
        "### 1.2 ì†ì‹¤ í•¨ìˆ˜ (Loss Function)\n",
        "ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ **ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´**ë¥¼ ê³„ì‚°í•´ì•¼ í•¨.  \n",
        "ëŒ€í‘œì ìœ¼ë¡œ **í‰ê· ì œê³±ì˜¤ì°¨(MSE, Mean Squared Error)** ì‚¬ìš©.  \n",
        "\n",
        "$$\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "765b4635",
      "metadata": {},
      "source": [
        "### 1.3 ê²½ì‚¬ í•˜ê°•ë²• (Gradient Descent)\n",
        "- ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ ë°©ë²•  \n",
        "- íŒŒë¼ë¯¸í„° w, bë¥¼ ì¡°ê¸ˆì”© ì¡°ì •í•˜ì—¬ MSEë¥¼ ì¤„ì—¬ë‚˜ê°  \n",
        "- **í•™ìŠµë¥ (learning rate, Î·)**: ì–¼ë§ˆë‚˜ í¬ê²Œ ì´ë™í• ì§€ ì¡°ì ˆ  \n",
        "\n",
        "ì—…ë°ì´íŠ¸ ì‹:  \n",
        "$$\n",
        "w := w - \\eta \\frac{\\partial L}{\\partial w}, \\quad b := b - \\eta \\frac{\\partial L}{\\partial b}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb81d5af",
      "metadata": {},
      "source": [
        "### 1.4 Numpyë¡œ ì§ì ‘ êµ¬í˜„í•˜ê¸°\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# ì„ í˜• íšŒê·€(Linear Regression)ë¥¼ ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ìµœì†Œ ì˜ˆì œ\n",
        "# y â‰ˆ w*x + b í˜•íƒœì˜ 1ì°¨ ëª¨ë¸ì„ ê°€ì •í•˜ê³ , MSE(í‰ê· ì œê³±ì˜¤ì°¨)ë¥¼ ìµœì†Œí™”í•˜ëŠ” w, bë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
        "# - X: ì…ë ¥(íŠ¹ì§•) ë²¡í„°, shape: (N,)\n",
        "# - y: ì •ë‹µ(íƒ€ê¹ƒ) ë²¡í„°, shape: (N,)\n",
        "# - w, b: í•™ìŠµí•  íŒŒë¼ë¯¸í„°(ìŠ¤ì¹¼ë¼)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# ë°ì´í„° (ê³µë¶€ ì‹œê°„ -> ì ìˆ˜)\n",
        "# ì˜ˆì‹œë¡œ ì™„ë²½í•œ ì„ í˜•ê´€ê³„ y = 2x ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "X = np.array([1, 2, 3, 4, 5], dtype=float)\n",
        "y = np.array([2, 4, 6, 8, 10], dtype=float)  # y = 2x ê´€ê³„\n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”\n",
        "# w: ê¸°ìš¸ê¸°(ìŠ¤ì¹¼ë¼), b: ì ˆí¸(ìŠ¤ì¹¼ë¼)\n",
        "w = 0.0\n",
        "b = 0.0\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "# lr(learning rate): í•œ ë²ˆì˜ ì—…ë°ì´íŠ¸ì—ì„œ ì´ë™í•˜ëŠ” í¬ê¸°\n",
        "# epochs: ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•˜ì—¬ í•™ìŠµí• ì§€\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# ìƒ˜í”Œ ìˆ˜ (í¸ë¯¸ë¶„ì—ì„œ í‰ê· ì„ ë‚´ê¸° ìœ„í•´ ì‚¬ìš©)\n",
        "N = len(X)\n",
        "\n",
        "# ê²½ì‚¬ í•˜ê°•ë²• ë£¨í”„\n",
        "for _ in range(epochs):\n",
        "    # 1) ìˆœì „íŒŒ(Forward): í˜„ì¬ íŒŒë¼ë¯¸í„°ë¡œ ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "    # y_pred_i = w*X_i + b\n",
        "    y_pred = w * X + b  # shape: (N,)\n",
        "\n",
        "    # 2) ì˜¤ì°¨(Error) ê³„ì‚°: ì˜ˆì¸¡ - ì •ë‹µ\n",
        "    # error_i = y_pred_i - y_i\n",
        "    error = y_pred - y  # shape: (N,)\n",
        "\n",
        "    # (ì°¸ê³ ) ì†ì‹¤ í•¨ìˆ˜ë¥¼ MSEë¡œ ë‘ë©´:\n",
        "    # L = (1/N) * Î£ (y_pred_i - y_i)^2\n",
        "    # ì—¬ê¸°ì„œëŠ” ë§¤ ìŠ¤í…ë§ˆë‹¤ Lì„ êµ³ì´ ì¶œë ¥í•˜ì§„ ì•Šì§€ë§Œ, ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.\n",
        "    # L = (1.0 / N) * np.sum(error ** 2)\n",
        "\n",
        "    # 3) ì—­ì „íŒŒ(Gradient) ê³„ì‚°\n",
        "    # MSEì— ëŒ€í•œ w, bì˜ í¸ë¯¸ë¶„(ë²¡í„°/í–‰ë ¬ ë¯¸ë¶„ ê²°ê³¼)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "    # dL/dw = (2/N) * Î£ (y_pred_i - y_i) * X_i  = (2/N) * (error Â· X)\n",
        "    # dL/db = (2/N) * Î£ (y_pred_i - y_i)        = (2/N) * sum(error)\n",
        "    dw = (2.0 / N) * np.dot(error, X)   # ìŠ¤ì¹¼ë¼\n",
        "    db = (2.0 / N) * np.sum(error)      # ìŠ¤ì¹¼ë¼\n",
        "\n",
        "    # 4) íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸(ê²½ì‚¬ í•˜ê°•)\n",
        "    # w := w - lr * dL/dw\n",
        "    # b := b - lr * dL/db\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    # (ì„ íƒ) í•™ìŠµ ê³¼ì •ì„ ë³´ê³  ì‹¶ë‹¤ë©´ ì£¼ê¸°ì ìœ¼ë¡œ ì†ì‹¤ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "    # if _ % 100 == 0:\n",
        "    #     print(f\"epoch={_:4d}  L={L:.6f}  w={w:.4f}  b={b:.4f}\")\n",
        "\n",
        "# í•™ìŠµëœ íŒŒë¼ë¯¸í„°ì™€ ìµœì¢… ì˜ˆì¸¡ ì¶œë ¥\n",
        "print(\"í•™ìŠµëœ w:\", w)         # ì´ë¡ ì  ì •ë‹µì€ 2.0ì— ìˆ˜ë ´\n",
        "print(\"í•™ìŠµëœ b:\", b)         # ì´ë¡ ì  ì •ë‹µì€ 0.0ì— ìˆ˜ë ´\n",
        "print(\"ì˜ˆì¸¡ y:\", w * X + b)   # ê° Xì— ëŒ€í•œ ìµœì¢… ì˜ˆì¸¡ê°’\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0aa2bd9",
      "metadata": {},
      "source": [
        "### 1.5 scikit-learnìœ¼ë¡œ ì„ í˜• íšŒê·€ êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cb2d48",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# ì…ë ¥ì„ 2Dë¡œ ë³€í™˜\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"íšŒê·€ ê³„ìˆ˜ w:\", model.coef_)\n",
        "print(\"ì ˆí¸ b:\", model.intercept_)\n",
        "print(\"ì˜ˆì¸¡:\", model.predict([[6]]))  # ê³µë¶€ì‹œê°„ 6ì‹œê°„ â†’ ì ìˆ˜ ì˜ˆì¸¡"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6695e173",
      "metadata": {},
      "source": [
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì„ í˜• íšŒê·€ëŠ” ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê´€ê³„ë¥¼ ì§ì„ ìœ¼ë¡œ ëª¨ë¸ë§í•œë‹¤.  \n",
        "- ì†ì‹¤ í•¨ìˆ˜(MSE)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•œë‹¤.  \n",
        "- ê²½ì‚¬ í•˜ê°•ë²•ì€ w, bë¥¼ ì¡°ì •í•˜ë©° ì˜¤ì°¨ë¥¼ ì¤„ì´ëŠ” ê³¼ì •ì´ë‹¤.  \n",
        "- `scikit-learn`ì„ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ì„ í˜• íšŒê·€ë¥¼ ì ìš©í•  ìˆ˜ ìˆë‹¤.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0b3cbc",
      "metadata": {},
      "source": [
        "## 2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ (Multiple Linear Regression)\n",
        "\n",
        "### 2.1 ê°œë…\n",
        "- ë‹¨ìˆœ ì„ í˜• íšŒê·€ëŠ” ì…ë ¥ì´ í•˜ë‚˜ì¼ ë•Œ \\( y = wx + b \\)  \n",
        "- ë‹¤ì¤‘ ì„ í˜• íšŒê·€ëŠ” ì…ë ¥ì´ ì—¬ëŸ¬ ê°œì¼ ë•Œ ì‚¬ìš©  \n",
        "\n",
        "$$\n",
        "y = w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n + b\n",
        "$$\n",
        "\n",
        "ì˜ˆ: ì§‘ê°’ ì˜ˆì¸¡  \n",
        "- $( x_1 $): ë°© ê°œìˆ˜  \n",
        "- $( x_2 $): í‰ìˆ˜  \n",
        "- $( x_3 $): ìœ„ì¹˜ ì§€ìˆ˜  \n",
        "\n",
        "\n",
        "\n",
        "### 2.2 ì†ì‹¤ í•¨ìˆ˜\n",
        "- ì—¬ì „íˆ í‰ê· ì œê³±ì˜¤ì°¨(MSE)ë¥¼ ì‚¬ìš©  \n",
        "- ì—¬ëŸ¬ ê°œì˜ w(ê°€ì¤‘ì¹˜)ì™€ b(ì ˆí¸)ë¥¼ ë™ì‹œì— í•™ìŠµ  \n",
        "\n",
        "\n",
        "\n",
        "### 2.3 ê²½ì‚¬ í•˜ê°•ë²•\n",
        "- íŒŒë¼ë¯¸í„° ë²¡í„° $( \\vec{w} $)ë¥¼ í•™ìŠµ  \n",
        "- ì—…ë°ì´íŠ¸ ì‹:  \n",
        "\n",
        "$$\n",
        "\\vec{w} := \\vec{w} - \\eta \\nabla_w L, \\quad b := b - \\eta \\frac{\\partial L}{\\partial b}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205d9095",
      "metadata": {
        "vscode": {
          "languageId": "ini"
        }
      },
      "source": [
        "### 2.4 Numpyë¡œ êµ¬í˜„í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d6a498",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ë°ì´í„° (ë°© ê°œìˆ˜, í‰ìˆ˜) â†’ ì§‘ê°’\n",
        "X = np.array([[1, 30],\n",
        "              [2, 50],\n",
        "              [3, 70],\n",
        "              [4, 100]])   # ì…ë ¥ íŠ¹ì„± 2ê°œ\n",
        "y = np.array([200, 400, 600, 1000])   # ì¶œë ¥\n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0.0\n",
        "lr = 0.0001\n",
        "epochs = 1000\n",
        "\n",
        "# ê²½ì‚¬ í•˜ê°•ë²•\n",
        "for _ in range(epochs):\n",
        "    y_pred = np.dot(X, w) + b\n",
        "    error = y_pred - y\n",
        "    \n",
        "    dw = (2/len(X)) * np.dot(X.T, error)\n",
        "    db = (2/len(X)) * np.sum(error)\n",
        "    \n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "print(\"í•™ìŠµëœ w:\", w)\n",
        "print(\"í•™ìŠµëœ b:\", b)\n",
        "print(\"ì˜ˆì¸¡:\", np.dot(X, w) + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa56b7a9",
      "metadata": {
        "vscode": {
          "languageId": "ini"
        }
      },
      "source": [
        "### 2.5 ì •ê·œë°©ì •ì‹ (Normal Equation)\n",
        "- ê²½ì‚¬ í•˜ê°•ë²• ëŒ€ì‹ , ìˆ˜í•™ì ìœ¼ë¡œ **í•´ë¥¼ ì§ì ‘ ê³„ì‚°**í•  ìˆ˜ë„ ìˆìŒ  \n",
        "\n",
        "$$\n",
        "\\vec{w} = (X^T X)^{-1} X^T y\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9804d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì •ê·œë°©ì •ì‹ìœ¼ë¡œ í•´ êµ¬í•˜ê¸°\n",
        "X_b = np.c_[np.ones((X.shape[0], 1)), X]  # b(ì ˆí¸) ì¶”ê°€\n",
        "theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "print(\"ì •ê·œë°©ì •ì‹ í•´:\", theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48221a66",
      "metadata": {},
      "source": [
        "### 2.6 scikit-learnìœ¼ë¡œ ë‹¤ì¤‘ íšŒê·€ êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f0f0f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"íšŒê·€ ê³„ìˆ˜ w:\", model.coef_)\n",
        "print(\"ì ˆí¸ b:\", model.intercept_)\n",
        "print(\"ì˜ˆì¸¡:\", model.predict([[3, 80]]))  # ë°© 3ê°œ, 80í‰ â†’ ì§‘ê°’ ì˜ˆì¸¡"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8d51fd",
      "metadata": {
        "vscode": {
          "languageId": "ini"
        }
      },
      "source": [
        "### 2.7 ê²½ì‚¬ í•˜ê°•ë²• vs ì •ê·œë°©ì •ì‹\n",
        "- **ê²½ì‚¬ í•˜ê°•ë²•**  \n",
        "  - ë°˜ë³µì ìœ¼ë¡œ ìµœì í•´ë¥¼ ê·¼ì‚¬  \n",
        "  - ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì— ì í•© (ë¹…ë°ì´í„°)  \n",
        "- **ì •ê·œë°©ì •ì‹**  \n",
        "  - í•œ ë²ˆì˜ ê³„ì‚°ìœ¼ë¡œ í•´ êµ¬í•¨  \n",
        "  - ë°ì´í„° í¬ê¸°ê°€ ì‘ì„ ë•Œ íš¨ìœ¨ì   \n",
        "  - í•˜ì§€ë§Œ $( (X^TX)^{-1} $) ê³„ì‚°ì— ë¹„ìš©ì´ í¼ (O(nÂ³))  \n",
        "\n",
        "\n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ë‹¤ì¤‘ ì„ í˜• íšŒê·€ëŠ” ì—¬ëŸ¬ ì…ë ¥ ë³€ìˆ˜ë¥¼ ë™ì‹œì— ê³ ë ¤í•  ìˆ˜ ìˆë‹¤.  \n",
        "- ì†ì‹¤ í•¨ìˆ˜ëŠ” MSE, í•™ìŠµì€ ê²½ì‚¬ í•˜ê°•ë²• ë˜ëŠ” ì •ê·œë°©ì •ì‹ìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤.  \n",
        "- `scikit-learn`ì„ ì‚¬ìš©í•˜ë©´ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.  \n",
        "- ê²½ì‚¬ í•˜ê°•ë²•ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì—, ì •ê·œë°©ì •ì‹ì€ ì†Œê·œëª¨ ë°ì´í„°ì— ì í•©í•˜ë‹¤.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cfe4a4",
      "metadata": {},
      "source": [
        "## 3. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\n",
        "\n",
        "### 3.1 ê°œë…\n",
        "- **ì„ í˜• íšŒê·€**ëŠ” ì—°ì†ê°’ ì˜ˆì¸¡ â†’ íšŒê·€ ë¬¸ì œì— ì í•©  \n",
        "- **ë¡œì§€ìŠ¤í‹± íšŒê·€**ëŠ” ë²”ì£¼í˜• ê°’ ì˜ˆì¸¡ â†’ ë¶„ë¥˜ ë¬¸ì œì— ì í•©  \n",
        "- ì˜ˆ: ìŠ¤íŒ¸ë©”ì¼(ìŠ¤íŒ¸/ì •ìƒ), ì‹œí—˜ ê²°ê³¼(í•©ê²©/ë¶ˆí•©ê²©)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f2de6e",
      "metadata": {},
      "source": [
        "### 3.2 ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ (Sigmoid Function)\n",
        "- ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ í•µì‹¬: ì…ë ¥ê°’ì„ **0~1 ì‚¬ì´ í™•ë¥ **ë¡œ ë³€í™˜  \n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "- z = \\( w x + b \\)  \n",
        "\n",
        "\n",
        "<img src=\"image/sigmoid.jpg\" alt=\"sigmoid\" width=\"400\">\n",
        "\n",
        "ì´ë¯¸ì§€ ì¶œì²˜ : https://en.wikipedia.org/wiki/Sigmoid_function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1dbd3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = sigmoid(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title(\"Sigmoid Function\")\n",
        "plt.xlabel(\"z\")\n",
        "plt.ylabel(\"Ïƒ(z)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40fa0a01",
      "metadata": {},
      "source": [
        "### 3.3 ê²°ì • ê²½ê³„ (Decision Boundary)\n",
        "- ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ê²°ê³¼ â‰¥ 0.5 â†’ 1 (True)  \n",
        "- ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ê²°ê³¼ < 0.5 â†’ 0 (False)  \n",
        "\n",
        "ì¦‰, í™•ë¥ ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7829a75",
      "metadata": {},
      "source": [
        "### 3.4 ì†ì‹¤ í•¨ìˆ˜ (Log Loss)\n",
        "- íšŒê·€ì—ì„œëŠ” MSE ì‚¬ìš©  \n",
        "- ë¶„ë¥˜ì—ì„œëŠ” **Log Loss (Cross-Entropy Loss)** ì‚¬ìš©  \n",
        "\n",
        "$$\n",
        "L = -\\frac{1}{n} \\sum_{i=1}^n \\Big[y_i \\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)\\Big]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d16b6a33",
      "metadata": {},
      "source": [
        "### 3.5 Numpyë¡œ êµ¬í˜„í•˜ê¸° (ì´ì§„ ë¶„ë¥˜)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "683a74d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„°: ê³µë¶€ ì‹œê°„(x) â†’ í•©ê²© ì—¬ë¶€(y: 0 or 1)\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([0, 0, 0, 1, 1])  \n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”\n",
        "w = 0.0\n",
        "b = 0.0\n",
        "lr = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# ê²½ì‚¬ í•˜ê°•ë²•\n",
        "for _ in range(epochs):\n",
        "    z = w*X + b\n",
        "    y_pred = sigmoid(z)\n",
        "    \n",
        "    # ì˜¤ì°¨\n",
        "    error = y_pred - y\n",
        "    \n",
        "    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "    dw = np.dot(error, X) / len(X)\n",
        "    db = np.sum(error) / len(X)\n",
        "    \n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "print(\"í•™ìŠµëœ w:\", w)\n",
        "print(\"í•™ìŠµëœ b:\", b)\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "test = np.array([2.5, 3.5, 5])\n",
        "pred = sigmoid(w*test + b)\n",
        "print(\"ì˜ˆì¸¡ í™•ë¥ :\", pred)\n",
        "print(\"ë¶„ë¥˜ ê²°ê³¼:\", (pred >= 0.5).astype(int))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eda7945",
      "metadata": {},
      "source": [
        "### 3.6 scikit-learnìœ¼ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7caf422f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = X.reshape(-1, 1)  # ì…ë ¥ì„ 2Dë¡œ ë³€í™˜\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"ì˜ˆì¸¡ í™•ë¥ :\", model.predict_proba([[3], [4], [5]]))\n",
        "print(\"ë¶„ë¥˜ ê²°ê³¼:\", model.predict([[3], [4], [5]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c00c52",
      "metadata": {},
      "source": [
        "### 3.7 ë‹¤ì¤‘ ë¶„ë¥˜ (Multiclass Classification)\n",
        "- ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ì— ì‚¬ìš©  \n",
        "- **OvR(One vs Rest)** ë°©ì‹ìœ¼ë¡œ ë‹¤ì¤‘ ë¶„ë¥˜ í™•ì¥ ê°€ëŠ¥  \n",
        "  - ì˜ˆ: ìˆ«ì(0~9) ì†ê¸€ì”¨ ë¶„ë¥˜  \n",
        "\n",
        "\n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ëŠ” ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.  \n",
        "- ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í™•ë¥ (0~1)ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤.  \n",
        "- ì†ì‹¤ í•¨ìˆ˜ëŠ” Log Loss (êµì°¨ ì—”íŠ¸ë¡œí”¼)ë¥¼ ì‚¬ìš©í•œë‹¤.  \n",
        "- `scikit-learn`ìœ¼ë¡œ ì†ì‰½ê²Œ ì´ì§„/ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8bec50a",
      "metadata": {},
      "source": [
        "### 4. Scikit-learn ëª¨ë¸ ì‚¬ìš©ë²• ìš”ì•½\n",
        "\n",
        "#### 1) ë¶„ë¥˜(Classification) ì˜ˆì œ â€” ë¡œì§€ìŠ¤í‹± íšŒê·€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612556c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¶„ë¥˜(Classification) ê¸°ë³¸ íë¦„:\n",
        "# 1) ë”ë¯¸ ë°ì´í„° ìƒì„± (make_classification)\n",
        "# 2) í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ (train_test_split)\n",
        "# 3) ëª¨ë¸ ìƒì„± ë° í•™ìŠµ (LogisticRegression.fit)\n",
        "# 4) ì˜ˆì¸¡ (predict, predict_proba)\n",
        "# 5) ì„±ëŠ¥ í‰ê°€ (ì •í™•ë„, F1, ROC-AUC, í˜¼ë™í–‰ë ¬)\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# 1) ë”ë¯¸ ë°ì´í„° ìƒì„±\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, # - n_samples: ìƒ˜í”Œ ìˆ˜\n",
        "    n_features=10, # - n_features: íŠ¹ì§• ìˆ˜\n",
        "    n_informative=5, # - n_informative: ì‹¤ì œë¡œ ìœ ìš©í•œ íŠ¹ì§• ìˆ˜\n",
        "    n_redundant=2, # - n_redundant: ì¤‘ë³µ íŠ¹ì§• ìˆ˜\n",
        "    random_state=42 # - random_state: ì¬í˜„ì„±\n",
        ")\n",
        "\n",
        "# 2) í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
        "# - stratify=y: ë¶„ë¥˜ì—ì„œëŠ” í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë„ë¡ ê¶Œì¥\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2,\n",
        "    random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3) ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
        "# - max_iter: ìˆ˜ë ´ ë³´ì¥ì„ ìœ„í•´ ì—¬ìœ  ìˆê²Œ ì„¤ì •\n",
        "# - n_jobs: ê°€ëŠ¥í•œ ê²½ìš° ë³‘ë ¬ ì²˜ë¦¬ (LogisticRegression ì¼ë¶€ solverì—ì„œë§Œ ì‚¬ìš©)\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 4) ì˜ˆì¸¡\n",
        "y_pred = clf.predict(X_test)                    # ë¼ë²¨ ì˜ˆì¸¡(0/1)\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]        # ì–‘ì„±(1) í´ë˜ìŠ¤ í™•ë¥ \n",
        "\n",
        "# 5) ì„±ëŠ¥ í‰ê°€\n",
        "acc  = accuracy_score(y_test, y_pred)           # ì „ì²´ ì •í™•ë„\n",
        "prec = precision_score(y_test, y_pred)          # ì •ë°€ë„(ì–‘ì„± ì˜ˆì¸¡ì˜ ì •í™•ì„±)\n",
        "rec  = recall_score(y_test, y_pred)             # ì¬í˜„ìœ¨(ì–‘ì„± í¬ì°©ë¥ )\n",
        "f1   = f1_score(y_test, y_pred)                 # F1(ì •ë°€/ì¬í˜„ ì¡°í™”í‰ê· )\n",
        "auc  = roc_auc_score(y_test, y_prob)            # ROC-AUC(ì„ê³„ê°’ ë…ë¦½ ë¶„ë¦¬ë„)\n",
        "\n",
        "cm   = confusion_matrix(y_test, y_pred)         # í˜¼ë™í–‰ë ¬\n",
        "rep  = classification_report(y_test, y_pred)    # í´ë˜ìŠ¤ë³„ ì •ë°€/ì¬í˜„/F1 ìƒì„¸\n",
        "\n",
        "print(\"[Classification] Logistic Regression\")\n",
        "print(f\"Accuracy  : {acc:.4f}\")\n",
        "print(f\"Precision : {prec:.4f}\")\n",
        "print(f\"Recall    : {rec:.4f}\")\n",
        "print(f\"F1        : {f1:.4f}\")\n",
        "print(f\"ROC-AUC   : {auc:.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", rep)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a638bb27",
      "metadata": {},
      "source": [
        "### ê¸°ë³¸ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ë“¤ â€“ ì‹¤ìŠµ ë¬¸ì œ\n",
        "\n",
        "### ë¬¸ì œ 1. ë‹¨ìˆœ ì„ í˜• íšŒê·€ (Numpy êµ¬í˜„)\n",
        "X = [1, 2, 3, 4, 5], y = [2, 4, 6, 8, 10] ë°ì´í„°ë¥¼ ì´ìš©í•´  \n",
        "ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ ì„ í˜• íšŒê·€ë¥¼ í•™ìŠµí•˜ê³ , wì™€ bë¥¼ ì¶œë ¥í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "w, b = 0.0, 0.0\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "for _ in range(epochs):\n",
        "    y_pred = w*X + b\n",
        "    error = y_pred - y\n",
        "    \n",
        "    dw = (2/len(X)) * np.dot(error, X)\n",
        "    db = (2/len(X)) * np.sum(error)\n",
        "    \n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "print(\"w:\", w, \"b:\", b)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08aa7183",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65eee4f9",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ (ì •ê·œë°©ì •ì‹)\n",
        "ë°© ê°œìˆ˜ì™€ í‰ìˆ˜ë¡œ ì§‘ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë°ì´í„°ë¥¼ ë§Œë“¤ê³ , ì •ê·œë°©ì •ì‹ìœ¼ë¡œ íšŒê·€ ê³„ìˆ˜ë¥¼ êµ¬í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "X = np.array([[1, 30],\n",
        "              [2, 50],\n",
        "              [3, 70],\n",
        "              [4, 100]])\n",
        "y = np.array([200, 400, 600, 1000])\n",
        "\n",
        "X_b = np.c_[np.ones((X.shape[0], 1)), X]  # ì ˆí¸ ì¶”ê°€\n",
        "theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "print(\"ì •ê·œë°©ì •ì‹ í•´:\", theta)  # [ì ˆí¸, w1, w2]\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2585778e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0567f348",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 3. ì„ í˜• íšŒê·€ (scikit-learn)\n",
        "ì‚¬ì´í‚·ëŸ°ì˜ `LinearRegression`ì„ ì‚¬ìš©í•´, ê³µë¶€ ì‹œê°„ X=[1,2,3,4,5]ê³¼ ì ìˆ˜ y=[2,4,6,8,10] ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ , 6ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"íšŒê·€ ê³„ìˆ˜:\", model.coef_)\n",
        "print(\"ì ˆí¸:\", model.intercept_)\n",
        "print(\"6ì‹œê°„ ì˜ˆì¸¡:\", model.predict([[6]]))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0e00ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e14aea7",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 4. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Numpy êµ¬í˜„)\n",
        "X = [1, 2, 3, 4, 5], y = [0, 0, 0, 1, 1] ë°ì´í„°ì—ì„œ  \n",
        "ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ í•™ìŠµí•œ í›„, X=3, 4, 5ì— ëŒ€í•œ í™•ë¥ ê³¼ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([0, 0, 0, 1, 1])\n",
        "\n",
        "w, b = 0.0, 0.0\n",
        "lr = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "for _ in range(epochs):\n",
        "    z = w*X + b\n",
        "    y_pred = sigmoid(z)\n",
        "    error = y_pred - y\n",
        "    \n",
        "    dw = np.dot(error, X) / len(X)\n",
        "    db = np.sum(error) / len(X)\n",
        "    \n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "test = np.array([3, 4, 5])\n",
        "probs = sigmoid(w*test + b)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "print(\"í™•ë¥ :\", probs)\n",
        "print(\"ë¶„ë¥˜:\", preds)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87f7bfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe783fe",
      "metadata": {},
      "source": [
        "\n",
        "### ë¬¸ì œ 5. ë¡œì§€ìŠ¤í‹± íšŒê·€ (scikit-learn)\n",
        "ì‚¬ì´í‚·ëŸ°ì˜ `LogisticRegression`ì„ ì‚¬ìš©í•´,  \n",
        "X=[1,2,3,4,5], y=[0,0,0,1,1] ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ ,  \n",
        "X=3, 4, 5ì˜ ì˜ˆì¸¡ í™•ë¥ ê³¼ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([0, 0, 0, 1, 1])\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"ì˜ˆì¸¡ í™•ë¥ :\", model.predict_proba([[3], [4], [5]]))\n",
        "print(\"ë¶„ë¥˜ ê²°ê³¼:\", model.predict([[3], [4], [5]]))\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d6d21e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e36b07",
      "metadata": {},
      "source": [
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì„ í˜• íšŒê·€ëŠ” ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡, ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ëœë‹¤.  \n",
        "- ê²½ì‚¬ í•˜ê°•ë²•ì€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œ íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•˜ëŠ” ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.  \n",
        "- ì •ê·œë°©ì •ì‹ì€ ì†Œê·œëª¨ ë°ì´í„°ì—ì„œ í•´ë¥¼ ë¹ ë¥´ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  \n",
        "- `scikit-learn`ì„ ì‚¬ìš©í•˜ë©´ ë³µì¡í•œ ìˆ˜ì‹ì„ ì§ì ‘ êµ¬í˜„í•˜ì§€ ì•Šì•„ë„ ì‰½ê²Œ ëª¨ë¸ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤.  \n"
      ]
    }
  ],
  "metadata": {
    "encoded_email": [
      "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ=="
    ],
    "filename": "MS05X+q4sOuzuCDsp4Drj4Qg7ZWZ7Iq1IOyVjOqzoOumrOymmOuTpC5pcHluYg==",
    "inserted_date": [
      "2025-09-19"
    ],
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
