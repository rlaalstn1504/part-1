{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b58e625",
      "metadata": {},
      "source": [
        "#  ë¨¸ì‹ ëŸ¬ë‹ ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ\n",
        "\n",
        "ë¨¸ì‹ ëŸ¬ë‹ì€ ë‹¨ìˆœíˆ ì•Œê³ ë¦¬ì¦˜ë§Œ ì•„ëŠ” ê²ƒìœ¼ë¡œ ëë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n",
        "ì‹¤ì œ í˜„ì—…ì—ì„œëŠ” **í•™ìŠµ ì†ë„ê°€ ëŠë¦¬ê±°ë‚˜**, **ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê¸°ëŒ€ë³´ë‹¤ ë‚®ì€ ê²½ìš°**ê°€ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤.  \n",
        "\n",
        "ğŸ‘‰ ì´ë²ˆ í† í”½ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ í•µì‹¬ ê¸°ë²•ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤:  \n",
        "- ë°ì´í„° ì „ì²˜ë¦¬  \n",
        "- ì •ê·œí™”(Regularization)  \n",
        "- ëª¨ë¸ í‰ê°€ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹  \n",
        "\n",
        "## í•™ìŠµ ëª©í‘œ\n",
        "ì´ í† í”½ì„ ìˆ˜ê°•í•œ ë’¤, ìˆ˜ê°•ìƒì€ ë‹¤ìŒì„ í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "- ë‹¤ì–‘í•œ ë°ì´í„° ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì´í•´í•˜ê³  ì ìš©í•  ìˆ˜ ìˆë‹¤.  \n",
        "- ì •ê·œí™” ê¸°ë²•(L1, L2)ì„ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë‹¤.  \n",
        "- êµì°¨ ê²€ì¦ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆë‹¤.  \n",
        "\n",
        "\n",
        "## ëª©ì°¨\n",
        "\n",
        "### 0. ë“¤ì–´ê°€ê¸°\n",
        "- ì™œ \"ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ\"ê°€ ì¤‘ìš”í•œê°€?  \n",
        "- ë°ì´í„° ì „ì²˜ë¦¬ â†’ ì •ê·œí™” â†’ ëª¨ë¸ í‰ê°€ & íŠœë‹ìœ¼ë¡œ ì´ì–´ì§€ëŠ” íë¦„  \n",
        "\n",
        "\n",
        "### 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "- Feature Scaling\n",
        "  - Normalization (0~1 ë²”ìœ„)\n",
        "  - Standardization (í‰ê· =0, í‘œì¤€í¸ì°¨=1)\n",
        "  - scikit-learn ì‹¤ìŠµ\n",
        "- One-hot Encoding\n",
        "  - ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
        "  - pandas `get_dummies()` ì‹¤ìŠµ\n",
        "\n",
        "\n",
        "\n",
        "### 2. ì •ê·œí™” (Regularization)\n",
        "- Bias(í¸í–¥) vs Variance(ë¶„ì‚°)  \n",
        "- Bias-Variance Tradeoff ê°œë…  \n",
        "- ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™” ê¸°ë²•\n",
        "  - L1 ì •ê·œí™” (Lasso)\n",
        "  - L2 ì •ê·œí™” (Ridge)\n",
        "- scikit-learn ì‹¤ìŠµ: Lasso, Ridge íšŒê·€ ë¹„êµ\n",
        "\n",
        "\n",
        "\n",
        "### 3. ëª¨ë¸ í‰ê°€ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ\n",
        "- kê²¹ êµì°¨ ê²€ì¦ (k-Fold Cross Validation)  \n",
        "  - scikit-learn `cross_val_score` ì‹¤ìŠµ\n",
        "- ê·¸ë¦¬ë“œ ì„œì¹˜ (Grid Search)  \n",
        "  - scikit-learn `GridSearchCV` ì‹¤ìŠµ\n",
        "- ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¾ê¸°  \n",
        "\n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì „ì²˜ë¦¬ì™€ ì •ê·œí™”ëŠ” ëª¨ë¸ ì„±ëŠ¥ì— ì§ì ‘ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤.  \n",
        "- Regularizationì€ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” í•µì‹¬ ë„êµ¬ì´ë‹¤.  \n",
        "- êµì°¨ ê²€ì¦ê³¼ ê·¸ë¦¬ë“œ ì„œì¹˜ëŠ” ëª¨ë¸ í‰ê°€ì™€ ì„±ëŠ¥ ê°œì„ ì˜ í‘œì¤€ ì ˆì°¨ì´ë‹¤.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f13ba0b",
      "metadata": {},
      "source": [
        "# 0. ë“¤ì–´ê°€ê¸°\n",
        "\n",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ \"ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ\" ë§Œë“¤ê¸° ìœ„í•´ ê°€ì¥ ë¨¼ì € í•´ì•¼ í•  ì¼ì€ **ë°ì´í„° ì „ì²˜ë¦¬(Data Preprocessing)** ì…ë‹ˆë‹¤.  \n",
        "- í˜„ì‹¤ ë°ì´í„°ëŠ” í¬ê¸° ë‹¨ìœ„ê°€ ì œê°ê° (ì˜ˆ: í‚¤=cm, ëª¸ë¬´ê²Œ=kg, ì›”ìˆ˜ì…=ë§Œì›)  \n",
        "- ìˆ«ì ë²”ìœ„ê°€ ë‹¤ë¥´ë©´, ëª¨ë¸ì´ íŠ¹ì • íŠ¹ì„±ì— **ê³¼ë„í•˜ê²Œ ì˜í–¥ì„ ë°›ìŒ**  \n",
        "- ë”°ë¼ì„œ ë°ì´í„°ë¥¼ ì ì ˆíˆ ìŠ¤ì¼€ì¼ë§(Scaling)í•˜ê³  ë³€í™˜í•´ì•¼ í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "### ì˜ˆì‹œ: íŠ¹ì„± ê°„ ë²”ìœ„ ì°¨ì´ ë¬¸ì œ\n",
        "\n",
        "ë°ì´í„°ì— ë‘ ê°œì˜ íŠ¹ì„±ì´ ìˆë‹¤ê³  í•©ì‹œë‹¤:\n",
        "\n",
        "- \\(x_1\\): **í‚¤ ë¹„ìœ¨** â†’ ê°’ì˜ ë²”ìœ„: 0 ~ 1  \n",
        "- \\(x_2\\): **ë…„ ìˆ˜ì…** â†’ ê°’ì˜ ë²”ìœ„: 4000 ~ 10000  \n",
        "\n",
        "### ë¬¸ì œì \n",
        "- ë‘ íŠ¹ì„±ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´, ëª¨ë¸ì€ ê³„ì‚° ê³¼ì •ì—ì„œ **ê°’ì˜ í¬ê¸°ê°€ í° $(x_2$) (1000~2000)** ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ê²Œ ë¨.  \n",
        "- ì‹¤ì œë¡œëŠ” $(x_1$) (í‚¤ ë¹„ìœ¨)ë„ ì¤‘ìš”í•œë°, **ìˆ«ì ìŠ¤ì¼€ì¼ ì°¨ì´ ë•Œë¬¸ì— ëª¨ë¸ì´ ë¬´ì‹œ**í•  ìˆ˜ ìˆìŒ.  \n",
        "\n",
        "\n",
        "### ì§ê´€ì  ë¹„ìœ \n",
        "- ì–´ë–¤ í•™ìƒì˜ ì„±ì ì„ ì˜ˆë¡œ ë“¤ì–´ë´…ì‹œë‹¤:\n",
        "  - **ê³¼ëª© A (ì¶œì„ì ìˆ˜)**: 0~1ì   \n",
        "  - **ê³¼ëª© B (ì‹œí—˜ì ìˆ˜)**: 1000~2000ì   \n",
        "\n",
        "ì´ì ì„ ë‹¨ìˆœ í•©ìœ¼ë¡œ ê³„ì‚°í•˜ë©´?  \n",
        "- ê³¼ëª© A ì ìˆ˜ëŠ” ì•„ë¬´ë¦¬ ë³€í•´ë„ 1ì  ì°¨ì´  \n",
        "- ê³¼ëª© B ì ìˆ˜ëŠ” ìµœì†Œ 1000ì  ì°¨ì´  \n",
        "\n",
        "ğŸ‘‰ ë‹¹ì—°íˆ **ì‹œí—˜ì ìˆ˜(ê³¼ëª© B)** ê°€ ëª¨ë“  ê²°ê³¼ë¥¼ ì¢Œìš°í•˜ê²Œ ë¨ â†’ ì¶œì„ì ìˆ˜ëŠ” ì‚¬ì‹¤ìƒ ë¬´ì‹œë¨.  \n",
        "\n",
        "\n",
        "### í•´ê²° ë°©ë²•\n",
        "- ë°ì´í„°ë¥¼ **ìŠ¤ì¼€ì¼ë§**í•˜ì—¬ ë‘ íŠ¹ì„±ì´ ë¹„ìŠ·í•œ ë²”ìœ„ë¥¼ ê°–ë„ë¡ ë³€í™˜í•´ì•¼ í•¨.\n",
        "- ì˜ˆ:\n",
        "  - Min-Max Scaling â†’ ëª¨ë“  ê°’ì„ 0~1 ì‚¬ì´ë¡œ ë§ì¶¤  \n",
        "  - Standardization â†’ í‰ê· =0, í‘œì¤€í¸ì°¨=1ë¡œ ë³€í™˜  \n",
        "\n",
        "ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ **íŠ¹ì„±ì˜ ì‹¤ì œ ì¤‘ìš”ë„**ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•  ìˆ˜ ìˆìŒ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ca85a2",
      "metadata": {},
      "source": [
        "# 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "\n",
        "## 1.1 Feature Scaling (íŠ¹ì„± ìŠ¤ì¼€ì¼ë§)\n",
        "\n",
        "### (1) Normalization (ì •ê·œí™”)\n",
        "- ë°ì´í„° ê°’ì„ **0~1 ì‚¬ì´ë¡œ ì••ì¶•**  \n",
        "- ê³µì‹:  \n",
        "  $$\n",
        "  x' = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
        "  $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edd787f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = np.array([[50], [200], [500]])\n",
        "scaler = MinMaxScaler()\n",
        "normalized = scaler.fit_transform(data)\n",
        "\n",
        "print(\"ì›ë³¸ ë°ì´í„°:\\n\", data)\n",
        "print(\"ì •ê·œí™” ë°ì´í„°:\\n\", normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf2e430",
      "metadata": {},
      "source": [
        "### (2) Standardization (í‘œì¤€í™”)\n",
        "- ë°ì´í„°ì˜ í‰ê· =0, í‘œì¤€í¸ì°¨=1ë¡œ ë§ì¶¤  \n",
        "- ê³µì‹:  \n",
        "  \n",
        "  $z = \\frac{x - \\mu}{\\sigma}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29723c54",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = np.array([[50], [200], [500]])\n",
        "scaler = StandardScaler()\n",
        "standardized = scaler.fit_transform(data)\n",
        "\n",
        "print(\"í‘œì¤€í™” ë°ì´í„°:\\n\", standardized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7539b19f",
      "metadata": {},
      "source": [
        "ğŸ‘‰ ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent) ê¸°ë°˜ ëª¨ë¸ì€ **ìŠ¤ì¼€ì¼ë§ì´ í•„ìˆ˜ì **ì…ë‹ˆë‹¤.  \n",
        "íŠ¹ì„± ë²”ìœ„ê°€ ë‹¤ë¥´ë©´, ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ë¨¼ì € í•™ìŠµí• ì§€ í˜¼ë€ì´ ìƒê¸°ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a9f1f9",
      "metadata": {},
      "source": [
        "## 1.2 One-hot Encoding (ë²”ì£¼í˜• ë°ì´í„° ë³€í™˜)\n",
        "\n",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "ë”°ë¼ì„œ ë²”ì£¼í˜• ë°ì´í„°(ì˜ˆ: ì„±ë³„=ë‚¨/ì—¬, ì§€ì—­=ì„œìš¸/ë¶€ì‚°/ëŒ€êµ¬)ëŠ” **ìˆ«ì ë²¡í„°**ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
        "\n",
        "- **ë¬¸ì œì **: ë‹¨ìˆœíˆ \"ë‚¨=0, ì—¬=1\"ì²˜ëŸ¼ í•˜ë©´, **ìˆœì„œ/í¬ê¸° ê´€ê³„ê°€ ìƒê²¨ë²„ë¦¼**  \n",
        "- **í•´ê²°ì±…**: One-hot Encoding â†’ ê° ë²”ì£¼ë¥¼ ë³„ë„ì˜ ì—´ë¡œ ë¶„ë¦¬, í•´ë‹¹ ë²”ì£¼ì—ë§Œ 1, ë‚˜ë¨¸ì§€ëŠ” 0  \n",
        "\n",
        "### ì˜ˆì‹œ (Gender ì»¬ëŸ¼ ë³€í™˜ ì „/í›„)\n",
        "\n",
        "| Index | Gender |\n",
        "|-------|--------|\n",
        "| 0     | Male   |\n",
        "| 1     | Female |\n",
        "| 2     | Female |\n",
        "| 3     | Male   |\n",
        "\n",
        "ğŸ‘‡ One-hot Encoding ì ìš© í›„\n",
        "\n",
        "| Index | Gender_Female | Gender_Male |\n",
        "|-------|---------------|-------------|\n",
        "| 0     | 0             | 1           |\n",
        "| 1     | 1             | 0           |\n",
        "| 2     | 1             | 0           |\n",
        "| 3     | 0             | 1           |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712a8fdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"Gender\": [\"Male\", \"Female\", \"Female\", \"Male\"]})\n",
        "encoded = pd.get_dummies(df, columns=[\"Gender\"])\n",
        "\n",
        "print(df)\n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e6d322",
      "metadata": {},
      "source": [
        "ğŸ‘‰ ê²°ê³¼:  \n",
        "- \"Male\" â†’ [1, 0]  \n",
        "- \"Female\" â†’ [0, 1]  \n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- Normalization: ë°ì´í„° ë²”ìœ„ë¥¼ 0~1 ì‚¬ì´ë¡œ ë§ì¶¤  \n",
        "- Standardization: í‰ê· =0, í‘œì¤€í¸ì°¨=1ë¡œ ë§ì¶¤  \n",
        "- One-hot Encoding: ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜  \n",
        "- Feature Scalingì€ ê²½ì‚¬ í•˜ê°•ë²•ì˜ íš¨ìœ¨ì„ ë†’ì´ê³ , One-hot Encodingì€ ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2d3467",
      "metadata": {},
      "source": [
        "# 2. ì •ê·œí™” (Regularization)\n",
        "\n",
        "## 2.1 ì™œ ì •ê·œí™”ê°€ í•„ìš”í•œê°€?\n",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ í›ˆë ¨ ë°ì´í„°ì— ë„ˆë¬´ **ê³¼ì í•©(overfitting)** ë˜ê±°ë‚˜,  \n",
        "ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ **ê³¼ì†Œì í•©(underfitting)** ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.  \n",
        "\n",
        "- **ê³¼ì†Œì í•©(Underfitting)**: ëª¨ë¸ì´ ë‹¨ìˆœ â†’ ë°ì´í„° íŒ¨í„´ì„ ì˜ ëª» ì¡ìŒ  \n",
        "- **ê³¼ì í•©(Overfitting)**: ëª¨ë¸ì´ ë³µì¡ â†’ í›ˆë ¨ ë°ì´í„°ì—ëŠ” ì˜ ë§ì§€ë§Œ ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ë–¨ì–´ì§  \n",
        "\n",
        "  <img src=\"image/overfitting.png\" width=\"500\">\n",
        "\n",
        "ì´ë¯¸ì§€ ì¶œì²˜ : https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/\n",
        "\n",
        "ğŸ‘‰ ì •ê·œí™”(Regularization)ëŠ” **ëª¨ë¸ì´ ê³¼ì í•©ë˜ëŠ” ê²ƒì„ ë§‰ê³ , ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ë²•**ì…ë‹ˆë‹¤.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2649aa6",
      "metadata": {},
      "source": [
        "## 2.2 ì •ê·œí™” ê°œë…\n",
        "ì •ê·œí™”ëŠ” ëª¨ë¸ì´ **ë¶ˆí•„ìš”í•˜ê²Œ í° ê°€ì¤‘ì¹˜**ë¥¼ ê°€ì§€ì§€ ì•Šë„ë¡ ì œì•½ì„ ì£¼ì–´,  \n",
        "ê³¼ì í•©ì„ ë°©ì§€í•˜ê³  ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.  \n",
        "\n",
        "- **L1 ì •ê·œí™” (Lasso Regression)**  \n",
        "  - ê°€ì¤‘ì¹˜ì˜ ì ˆëŒ“ê°’ í•©ì„ íŒ¨ë„í‹°ë¡œ ë¶€ì—¬  \n",
        "  - ì¼ë¶€ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ **íŠ¹ì„± ì„ íƒ(feature selection)** íš¨ê³¼  \n",
        "\n",
        "- **L2 ì •ê·œí™” (Ridge Regression)**  \n",
        "  - ê°€ì¤‘ì¹˜ì˜ ì œê³±í•©ì„ íŒ¨ë„í‹°ë¡œ ë¶€ì—¬\n",
        "  - ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì¡°ê¸ˆì”© ì¤„ì—¬ ì•ˆì •ì ì¸ ëª¨ë¸ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cca3678",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2.3 scikit-learnìœ¼ë¡œ ê³¼ì í•© ë¬¸ì œ í•´ê²°\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
        "X = np.random.rand(100, 5) * 10\n",
        "y = 3*X[:,0] + 2*X[:,1] - X[:,2] + np.random.randn(100)*2\n",
        "\n",
        "# ë°ì´í„° ë¶„í• \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ì„ í˜• íšŒê·€\n",
        "lr = LinearRegression().fit(X_train, y_train)\n",
        "print(\"LinearRegression MSE:\", mean_squared_error(y_test, lr.predict(X_test)))\n",
        "\n",
        "# Ridge íšŒê·€ (L2)\n",
        "ridge = Ridge(alpha=1.0).fit(X_train, y_train)\n",
        "print(\"Ridge MSE:\", mean_squared_error(y_test, ridge.predict(X_test)))\n",
        "\n",
        "# Lasso íšŒê·€ (L1)\n",
        "lasso = Lasso(alpha=0.1).fit(X_train, y_train)\n",
        "print(\"Lasso MSE:\", mean_squared_error(y_test, lasso.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "835e2b8c",
      "metadata": {},
      "source": [
        "## 2.4 L1, L2 ì§ì ‘ ë¹„êµ\n",
        "- **L1 (Lasso)**: ì¼ë¶€ ê³„ìˆ˜=0 â†’ ë¶ˆí•„ìš”í•œ íŠ¹ì„± ì œê±° ê°€ëŠ¥  \n",
        "- **L2 (Ridge)**: ëª¨ë“  ê³„ìˆ˜ë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ ì•ˆì •ì ì¸ ëª¨ë¸  \n",
        "- ì‹¤ì œë¡œëŠ” L1+L2 í˜¼í•©í•œ **Elastic Net**ë„ ë§ì´ ì‚¬ìš©  \n",
        "\n",
        "\n",
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì •ê·œí™”ëŠ” ê³¼ì í•© ë°©ì§€ì™€ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì— í•µì‹¬ì ì´ë‹¤.  \n",
        "- L1(Lasso): ê°€ì¤‘ì¹˜ ì ˆëŒ“ê°’ í•© â†’ íŠ¹ì„± ì„ íƒ íš¨ê³¼  \n",
        "- L2(Ridge): ê°€ì¤‘ì¹˜ ì œê³±í•© â†’ ì•ˆì •ì ì¸ ëª¨ë¸  \n",
        "- `alpha` ê°’ì´ í´ìˆ˜ë¡ ì •ê·œí™” ê°•ë„ê°€ ì„¸ì§€ë©°, ë„ˆë¬´ í¬ë©´ ê³¼ì†Œì í•© ìœ„í—˜ì´ ìˆë‹¤.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080481f5",
      "metadata": {},
      "source": [
        "# 3. ëª¨ë¸ í‰ê°€ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ\n",
        "\n",
        "> ëª©ì : **í›ˆë ¨ ë°ì´í„°ì—ì„œë§Œ ì˜ ë§ëŠ” ëª¨ë¸**ì„ í”¼í•˜ê³ , **ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œë„ ì¼ê´€ë˜ê²Œ ì˜ ì‘ë™(ì¼ë°˜í™”)** í•˜ë„ë¡ í‰ê°€Â·íŠœë‹í•œë‹¤.\n",
        "\n",
        "\n",
        "## 3.1 ì™œ ëª¨ë¸ í‰ê°€ê°€ ì¤‘ìš”í•œê°€?\n",
        "- **í›ˆë ¨ ì„±ëŠ¥ = ì‹¤ì œ ì„±ëŠ¥ ì•„ë‹˜**: í›ˆë ¨ ë°ì´í„°ì— ë§ì¶˜ ì ìˆ˜ëŠ” ë‚™ê´€ì ì¼ ìˆ˜ ìˆìŒ(ê³¼ì í•©).\n",
        "- **ì¼ë°˜í™” í™•ì¸**: ë³´ì§€ ëª»í•œ ë°ì´í„°(ê²€ì¦/í…ŒìŠ¤íŠ¸)ì—ì„œ ì„±ëŠ¥ì„ í™•ì¸í•´ì•¼ í•¨.\n",
        "- **ì‹ ë¢°ì„±**: í‰ê°€ ì ˆì°¨ê°€ ì¬í˜„ ê°€ëŠ¥í•´ì•¼ í•˜ë©°, ë°ì´í„° ëˆ„ìˆ˜(leakage)ë¥¼ ë°©ì§€í•´ì•¼ í•¨."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa420c1",
      "metadata": {},
      "source": [
        "## 3.2 ë°ì´í„° ë¶„í•  ì „ëµ\n",
        "\n",
        "### (1) Hold-out ë¶„í• (ì˜ˆ: **8:1:1 = train:valid:test**)\n",
        "- **train**: í•™ìŠµ\n",
        "- **valid**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ/ëª¨ë¸ ë¹„êµ\n",
        "- **test**: ìµœì¢… ì„±ëŠ¥ ë³´ê³ (ë”± 1ë²ˆë§Œ ì‚¬ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8249b2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ë°ì´í„° ì ì¬\n",
        "# ------------------------------------------\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# ------------------------------------------\n",
        "# 8:1:1 ë¶„í•  (ê³„ì¸µí™” ë¶„í• : ê° í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)\n",
        "# ------------------------------------------\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "print(\"train/valid/test:\", X_train.shape, X_valid.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f4d51e",
      "metadata": {},
      "source": [
        "#### ë³€í˜• ì˜ˆì‹œ: **6:2:2**, **7:1.5:1.5** ë“±. ë°ì´í„°ê°€ ì ìœ¼ë©´ êµì°¨ ê²€ì¦ì„ ê¶Œì¥."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b76c831",
      "metadata": {},
      "source": [
        "### (2) ì‹œê³„ì—´(ìˆœì„œí˜•) ë°ì´í„°\n",
        "#### 1. íŠ¹ì§•\n",
        "- ë°ì´í„°ëŠ” ì‹œê°„ ìˆœì„œëŒ€ë¡œ ê¸°ë¡ë¨ (ì˜ˆ: ì£¼ì‹ ê°€ê²©, ë‚ ì”¨ ë°ì´í„°, ì„¼ì„œ ë°ì´í„°).\n",
        "- **ìˆœì„œê°€ ì¤‘ìš”**í•˜ë¯€ë¡œ ë¬´ì‘ìœ„ ì„ê¸°(shuffle) ê¸ˆì§€.  \n",
        "- í•­ìƒ **ê³¼ê±° â†’ ë¯¸ë˜** ìˆœì„œë¥¼ ì§€ì¼œì„œ í•™ìŠµí•´ì•¼ í•¨.  \n",
        "\n",
        "\n",
        "#### 2. ì˜¬ë°”ë¥¸ ë¶„í•  ë°©ì‹ (Sliding Window)\n",
        "- ì¼ë°˜ ë°ì´í„° ë¶„í• (`train_test_split`)ì€ ë¬´ì‘ìœ„ ì¶”ì¶œì´ ê°€ëŠ¥í•˜ì§€ë§Œ, ì‹œê³„ì—´ì€ ìˆœì„œë¥¼ ë³´ì¡´í•´ì•¼ í•¨.  \n",
        "- **Sliding Window**: ì¼ì • ê¸¸ì´ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë¬¶ì–´ì„œ(train window) ê·¸ ì§í›„ ë¯¸ë˜ êµ¬ê°„ì„ ì˜ˆì¸¡(valid window).  \n",
        "  - ì˜ˆ: \"ê³¼ê±° 3ì¼ â†’ ë‹¤ìŒ 1ì¼ ì˜ˆì¸¡\"  \n",
        "- ì¥ì : ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ì¼ì • â†’ ë”¥ëŸ¬ë‹/ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì— ë°”ë¡œ í™œìš© ê°€ëŠ¥.\n",
        "\n",
        "#### 3. ì½”ë“œ ì˜ˆì‹œ: Sliding Window ë°ì´í„°ì…‹ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad241b17",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ì˜ˆì œ ì‹œê³„ì—´ ë°ì´í„° (0 ~ 19)\n",
        "series = np.arange(20)\n",
        "\n",
        "def make_window_data(series, window=5, horizon=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(series) - window - horizon + 1):\n",
        "        X.append(series[i:i+window])            # ê³¼ê±° êµ¬ê°„\n",
        "        y.append(series[i+window:i+window+horizon])  # ì˜ˆì¸¡ êµ¬ê°„\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ê³¼ê±° 5ì¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒ 1ì¼ì„ ì˜ˆì¸¡\n",
        "X, y = make_window_data(series, window=5, horizon=1)\n",
        "\n",
        "print(\"X shape:\", X.shape)  # (ìƒ˜í”Œ ìˆ˜, window í¬ê¸°)\n",
        "print(\"y shape:\", y.shape)  # (ìƒ˜í”Œ ìˆ˜, horizon í¬ê¸°)\n",
        "print(\"ì²« ë²ˆì§¸ ìƒ˜í”Œ X:\", X[0], \"-> y:\", y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "851fe0ef",
      "metadata": {},
      "source": [
        "## 3.3 êµì°¨ ê²€ì¦(Cross Validation) ì¢…ë¥˜\n",
        "- **KFold**: ë¬´ì‘ìœ„ë¡œ Kë¶„í•  â†’ í•™ìŠµ/ê²€ì¦ KíšŒ ë°˜ë³µ í›„ í‰ê· .\n",
        "- **StratifiedKFold**: ë¶„ë¥˜ì—ì„œ **í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€**.\n",
        "    - **ì˜ˆì‹œ**: ì•” í™˜ì ë°ì´í„°(í™˜ì 10%, ì •ìƒì¸ 90%) â†’ ì¼ë°˜ KFoldëŠ” ì–´ë–¤ foldì—” í™˜ìê°€ ì•„ì˜ˆ ì—†ì„ ìˆ˜ë„ ìˆìŒ.  \n",
        "- **GroupKFold**: ë™ì¼ ê·¸ë£¹ì€ ê°™ì€ í´ë“œì—ë§Œ ë°°ì¹˜.\n",
        "    - **ì˜ˆì‹œ**: ë‚¨/ë…€ ë¥¼ ë§ì¶°ì•¼ í• ë•Œ ë™ì¼í•œ ì‚¬ëŒì˜ ì‚¬ì§„ì´ 2ì¥ì´ìƒ ì¡´ì¬í• ë•Œ ê°™ì€ ê·¸ë£¹(train/val/test)ì— ë°°ì¹˜\n",
        "- **TimeSeriesSplit**: ì‹œê³„ì—´ ì „ìš©(ì‹œê°„ ìˆœì„œ ìœ ì§€).\n",
        "- **RepeatedKFold/RepeatedStratifiedKFold**: KFold êµì°¨ê²€ì¦ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•´ ë¶„ì‚° ê°ì†Œ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed627848",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# ì…ë ¥ íŠ¹ì„± í–‰ë ¬(X)ê³¼ ì •ë‹µ ë²¡í„°(y) ë¶„ë¦¬\n",
        "# X : ê½ƒë°›ì¹¨ ê¸¸ì´, ê½ƒë°›ì¹¨ í­, ê½ƒì ê¸¸ì´, ê½ƒì í­ (4ê°œì˜ íŠ¹ì„±)\n",
        "# y : ë¶“ê½ƒ í’ˆì¢… (0=setosa, 1=versicolor, 2=virginica)\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„±\n",
        "# ë¶„ë¥˜(classification) ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” ì„ í˜• ëª¨ë¸\n",
        "# max_iter=200 : í•™ìŠµ ë°˜ë³µ íšŸìˆ˜ ì œí•œ (ê¸°ë³¸ê°’ì€ 100, ìˆ˜ë ´ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ëŠ˜ë¦¼)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# StratifiedKFold : ê° í´ë˜ìŠ¤ ë¹„ìœ¨(ë ˆì´ë¸” ë¶„í¬)ì„ ìœ ì§€í•˜ë©´ì„œ ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” K-ê²¹ êµì°¨ê²€ì¦ ë°©ë²•\n",
        "# n_splits=5 â†’ ë°ì´í„°ë¥¼ 5ê°œì˜ í´ë“œ(fold)ë¡œ ë‚˜ëˆ” (ì¦‰, 5ë²ˆì˜ í•™ìŠµ/í‰ê°€ ìˆ˜í–‰)\n",
        "# shuffle=True â†’ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì€ í›„ ë¶„í•  (ë°ì´í„° ìˆœì„œì— ì˜í•œ í¸í–¥ ë°©ì§€)\n",
        "# random_state=42 â†’ ë‚œìˆ˜ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ì„± í™•ë³´\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "# cross_val_score() : êµì°¨ ê²€ì¦ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•´ì£¼ëŠ” í•¨ìˆ˜\n",
        "# ì¸ì ì„¤ëª…:\n",
        "#   model   : ì‚¬ìš©í•  í•™ìŠµ ëª¨ë¸ (ì—¬ê¸°ì„œëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€)\n",
        "#   X, y    : ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ ë ˆì´ë¸”\n",
        "#   cv      : êµì°¨ê²€ì¦ ë¶„í•  ì „ëµ (StratifiedKFold ê°ì²´)\n",
        "#   scoring : ì„±ëŠ¥ í‰ê°€ ì§€í‘œ. ì—¬ê¸°ì„œëŠ” 'accuracy' (ì •í™•ë„)\n",
        "#\n",
        "# ì‹¤í–‰ ê³¼ì •:\n",
        "#   1. ë°ì´í„°ë¥¼ StratifiedKFoldì— ë”°ë¼ 5ê°œì˜ í´ë“œë¡œ ë‚˜ëˆ”\n",
        "#   2. ê° í´ë“œì— ëŒ€í•´ 1ê°œëŠ” í…ŒìŠ¤íŠ¸, ë‚˜ë¨¸ì§€ 4ê°œëŠ” í•™ìŠµìš©ìœ¼ë¡œ ì‚¬ìš©\n",
        "#   3. 5ë²ˆ ë°˜ë³µí•˜ì—¬ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°\n",
        "#   4. ê° ë°˜ë³µì—ì„œì˜ ì •í™•ë„ ì ìˆ˜ë¥¼ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜\n",
        "print(\"êµì°¨ ê²€ì¦ ì ìˆ˜:\", scores)\n",
        "print(\"í‰ê·  ì •í™•ë„:\", np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d3db86",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê° í´ë“œì˜ ì¸ë±ìŠ¤ í™•ì¸\n",
        "for fold_idx, (train_index, test_index) in enumerate(cv.split(X, y), start=1):\n",
        "    print(f\"\\nğŸ“‚ Fold {fold_idx}\")\n",
        "    print(f\"í•™ìŠµ ë°ì´í„° ì¸ë±ìŠ¤ ({len(train_index)}ê°œ): {train_index[:10]} ...\")  # ì•ë¶€ë¶„ë§Œ í‘œì‹œ\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¸ë±ìŠ¤ ({len(test_index)}ê°œ): {test_index[:10]} ...\")\n",
        "    print(f\"â†’ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y[test_index])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbe75dfc",
      "metadata": {},
      "source": [
        "#### **TIP**: ë°ì´í„° ì „ì²˜ë¦¬(ìŠ¤ì¼€ì¼ë§)ëŠ” ë°˜ë“œì‹œ **êµì°¨ ê²€ì¦ í´ë“œ ì•ˆì—ì„œ** `fit`ë˜ì–´ì•¼ í•¨ â†’ `Pipeline` ì‚¬ìš©!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3c0679",
      "metadata": {},
      "source": [
        "## 3.4 í‰ê°€ ì§€í‘œ ì„ íƒ ê°€ì´ë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef0a01b",
      "metadata": {},
      "source": [
        "### 1) ë¶„ë¥˜(Classification)\n",
        "\n",
        "#### í˜¼ë™í–‰ë ¬(Confusion Matrix) í‘œ\n",
        "\n",
        "| ì‹¤ì œ \\ ì˜ˆì¸¡ | 0 (Negative)         | 1 (Positive)         |\n",
        "|-------------|-----------------------|-----------------------|\n",
        "| **0 (Negative)** | **TN**: ì§„ì§œ ìŒì„± (ì •ìƒ ì •ë‹µ) | **FP**: ê±°ì§“ ì–‘ì„± (ê±°ì§“ ê²½ë³´) |\n",
        "| **1 (Positive)** | **FN**: ê±°ì§“ ìŒì„± (ë†“ì¹¨)     | **TP**: ì§„ì§œ ì–‘ì„± (ì •ìƒ ê²€ì¶œ) |\n",
        "\n",
        "#### í˜¼ë™í–‰ë ¬(Confusion Matrix) ìš©ì–´ ì •ë¦¬\n",
        "- **TP (True Positive)**: ì‹¤ì œ 1ì´ê³ , ì˜ˆì¸¡ë„ 1  \n",
        "- **FP (False Positive)**: ì‹¤ì œ 0ì¸ë°, ì˜ˆì¸¡ì´ 1 (ê±°ì§“ ê²½ë³´)  \n",
        "- **TN (True Negative)**: ì‹¤ì œ 0ì´ê³ , ì˜ˆì¸¡ë„ 0  \n",
        "- **FN (False Negative)**: ì‹¤ì œ 1ì¸ë°, ì˜ˆì¸¡ì´ 0 (ë†“ì¹¨)\n",
        "\n",
        "#### **ì§€í‘œ ê³µì‹**  \n",
        " - Accuracy = (TP + TN) / (TP + FP + TN + FN)  \n",
        " - Precision = TP / (TP + FP)  \n",
        " - Recall = TP / (TP + FN)  \n",
        " - F1 = 2 Â· (Precision Â· Recall) / (Precision + Recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d13e74",
      "metadata": {},
      "source": [
        "| ì§€í‘œ | ì •ì˜/ì„¤ëª… | ì¥ì  | ì£¼ì˜í•  ì  / í™œìš© ìƒí™© |\n",
        "|------|-----------|------|------------------------|\n",
        "| **Accuracy** | ì „ì²´ ìƒ˜í”Œ ì¤‘ ì •ë‹µ ë¹„ìœ¨ | ì§ê´€ì , í•´ì„ ì‰¬ì›€ | í´ë˜ìŠ¤ ë¶ˆê· í˜•(ì˜ˆ: ì •ìƒ 99%, ì´ìƒ 1%)ì— ë§¤ìš° ì·¨ì•½ |\n",
        "| **Precision (ì •ë°€ë„)** | `ì˜ˆì¸¡=ì–‘ì„±` ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨ | ì˜ëª»ëœ ê²½ë³´(ì˜¤íƒ) ì¤„ì´ëŠ” ë° ì¤‘ìš” | ì–‘ì„± ë†“ì¹¨(ë¯¸íƒ)ì—ëŠ” ë‘”ê° |\n",
        "| **Recall (ì¬í˜„ìœ¨)** | ì‹¤ì œ ì–‘ì„± ì¤‘ ì˜ˆì¸¡=ì–‘ì„± ë¹„ìœ¨ | ì–‘ì„± ë†“ì¹˜ì§€ ì•ŠëŠ” ê²Œ ì¤‘ìš”í•  ë•Œ ìœ ë¦¬ | ì˜¤íƒ(ê±°ì§“ ì–‘ì„±)ì´ ë§ì•„ì§ˆ ìˆ˜ ìˆìŒ |\n",
        "| **F1 Score** | PrecisionÂ·Recallì˜ ì¡°í™” í‰ê·  | PrecisionÂ·Recall ê· í˜• í‰ê°€ | í•´ì„ì€ ë‹¤ì†Œ ì–´ë µì§€ë§Œ ë¶ˆê· í˜• ë°ì´í„°ì— ìì£¼ ì‚¬ìš© |\n",
        "| **ROC-AUC** | ëª¨ë“  ì„ê³„ê°’ì—ì„œ TPR vs FPR ê³¡ì„  ì•„ë˜ ë©´ì  | ì„ê³„ê°’ì— ë…ë¦½ì , ì „ë°˜ì  ì„±ëŠ¥ í‰ê°€ | í´ë˜ìŠ¤ ê·¹ì‹¬ ë¶ˆê· í˜•ì¼ ë•Œ ê³¼ëŒ€í‰ê°€ë  ìˆ˜ ìˆìŒ |\n",
        "| **PR-AUC** | Precision-Recall ê³¡ì„  ì•„ë˜ ë©´ì  | ì–‘ì„± í´ë˜ìŠ¤ í¬ì†Œí•  ë•Œ ìœ ë¦¬ | ROC-AUCë³´ë‹¤ í•´ì„ ì–´ë µì§€ë§Œ ë¶ˆê· í˜• ì‹¬í•  ë•Œ í•„ìˆ˜ |\n",
        "| **Top-k Accuracy** | ë‹¤ì¤‘ í´ë˜ìŠ¤ì—ì„œ ìƒìœ„ kê°œ ì˜ˆì¸¡ ì•ˆì— ì •ë‹µ ìˆëŠ”ì§€ | ì´ë¯¸ì§€ ë¶„ë¥˜(ì˜ˆ: Top-5 Accuracy)ì—ì„œ ìœ ë¦¬ | k ì„¤ì • í•„ìš” |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d448fcdd",
      "metadata": {},
      "source": [
        "### 2) íšŒê·€(Regression)\n",
        "\n",
        "| ì§€í‘œ | ì •ì˜/ì„¤ëª… | ì¥ì  | ì£¼ì˜í•  ì  / í™œìš© ìƒí™© |\n",
        "|------|-----------|------|------------------------|\n",
        "| **MAE (Mean Absolute Error)** | ì ˆëŒ“ê°’ ì˜¤ì°¨ í‰ê·  | í•´ì„ ì§ê´€ì , ì´ìƒì¹˜ ì˜í–¥ ì ìŒ | í° ì˜¤ì°¨ì— ë‘”ê° |\n",
        "| **MSE (Mean Squared Error)** | ì œê³± ì˜¤ì°¨ í‰ê·  | ë¯¸ë¶„/ìµœì í™”ì— ìœ ë¦¬ | í° ì˜¤ì°¨ì— ê³¼ë„í•œ íŒ¨ë„í‹° |\n",
        "| **RMSE (Root Mean Squared Error)** | ì œê³± ì˜¤ì°¨ì˜ ì œê³±ê·¼ | ì› ë‹¨ìœ„ ë³µì›, í° ì˜¤ì°¨ ê°•ì¡° | MAEë³´ë‹¤ ì´ìƒì¹˜ ë¯¼ê° |\n",
        "| **RÂ² (ê²°ì •ê³„ìˆ˜)** | ëª¨ë¸ì´ ë°ì´í„° ë¶„ì‚°ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€ (1=ì™„ë²½) | ìƒëŒ€ì  ì„±ëŠ¥ ë¹„êµì— ìœ ìš© | ë°ì´í„° ë¶„í¬ì— ë”°ë¼ ìŒìˆ˜ê°€ ë  ìˆ˜ ìˆìŒ |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea203bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# scoring ì˜ˆì‹œ: \"accuracy\", \"f1_macro\", \"roc_auc_ovr\", \"neg_mean_absolute_error\" ë“±"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f931a8cc",
      "metadata": {},
      "source": [
        "## 3.5 í•˜ì´í¼íŒŒë¼ë¯¸í„°ë€?\n",
        "- **íŒŒë¼ë¯¸í„°**: ëª¨ë¸ì´ **ë°ì´í„°ë¡œë¶€í„° í•™ìŠµ**í•˜ëŠ” ê°’ (ì˜ˆ: ì„ í˜•íšŒê·€ì˜ ê°€ì¤‘ì¹˜, NNì˜ W, b)\n",
        "- **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: ì‚¬ëŒì´ **ì‚¬ì „ì— ì„¤ì •**í•˜ëŠ” ê°’ (ì˜ˆ: ì •ê·œí™” ê°•ë„ C/alpha, íŠ¸ë¦¬ ê¹Šì´, ëŸ¬ë‹ë ˆì´íŠ¸)\n",
        "\n",
        "| ì•Œê³ ë¦¬ì¦˜ | ëŒ€í‘œ í•˜ì´í¼íŒŒë¼ë¯¸í„° | ì˜ë¯¸/ì˜í–¥ |\n",
        "|---|---|---|\n",
        "| LogisticRegression | C, penalty, solver | ì •ê·œí™” ê°•ë„, ê·œì œ í˜•íƒœ |\n",
        "| SVM | C, kernel, gamma | ë§ˆì§„/ë³µì¡ë„ ì œì–´, ì»¤ë„ í­ |\n",
        "| RandomForest | n_estimators, max_depth, min_samples_split | ì•™ìƒë¸” í¬ê¸°/ë³µì¡ë„ |\n",
        "| Ridge/Lasso | alpha | L2/L1 ì •ê·œí™” ê°•ë„ |\n",
        "| XGBoost/LightGBM | n_estimators, learning_rate, max_depth, subsample | ë¶€ìŠ¤íŒ… ë‹¨ê³„/í•™ìŠµë¥ /ë³µì¡ë„ |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc82f642",
      "metadata": {},
      "source": [
        "## 3.6 ê·¸ë¦¬ë“œ ì„œì¹˜(Grid Search) + íŒŒì´í”„ë¼ì¸(Pipeline) + ëˆ„ìˆ˜ ë°©ì§€\n",
        "\n",
        "### 1) Grid Searchë€?\n",
        "- ëª¨ë¸ì˜ **í•˜ì´í¼íŒŒë¼ë¯¸í„° í›„ë³´ ì§‘í•©**ì„ ì •ì˜í•˜ê³ ,  \n",
        "- êµì°¨ê²€ì¦(Cross Validation)ìœ¼ë¡œ ëª¨ë“  ì¡°í•©ì„ í‰ê°€í•´ **ìµœì  ì¡°í•©ì„ ì°¾ëŠ” ë°©ë²•**.  \n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52920de9",
      "metadata": {},
      "source": [
        "### 2) Pipelineì´ í•„ìš”í•œ ì´ìœ \n",
        "\n",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì—ëŠ” ë³´í†µ ì´ëŸ° ë‹¨ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n",
        "```\n",
        "[ë°ì´í„°] â†’ [ì „ì²˜ë¦¬ê¸°(ì˜ˆ: ìŠ¤ì¼€ì¼ëŸ¬)] â†’ [ëª¨ë¸ í•™ìŠµ]\n",
        "```\n",
        "\n",
        "\n",
        "#### âŒ ì˜ëª»ëœ ë°©ì‹ (ëˆ„ìˆ˜ ë°œìƒ)\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)  # âš ï¸ ì „ì²´ ë°ì´í„°ë¡œ í‰ê· /ë¶„ì‚° í•™ìŠµ (X_train+X_test ëª¨ë‘ í¬í•¨)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(model.score(X_test_scaled, y_test))\n",
        "```\n",
        "\n",
        "- ì—¬ê¸°ì„œëŠ” **í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë³´ê¹Œì§€ í‰ê· /ë¶„ì‚° í•™ìŠµì— ë“¤ì–´ê°**  \n",
        "- ì¦‰, ë¯¸ë˜(í…ŒìŠ¤íŠ¸)ì˜ ì •ë³´ë¥¼ ë¯¸ë¦¬ ë“¤ì—¬ë‹¤ë³¸ ì…ˆ â†’ í‰ê°€ ì ìˆ˜ê°€ ì‹¤ì œë³´ë‹¤ ë†’ê²Œ ë‚˜ì˜´ (ë°ì´í„° ëˆ„ìˆ˜)\n",
        "\n",
        "\n",
        "#### âœ… ì˜¬ë°”ë¥¸ ë°©ì‹ (Pipeline ì‚¬ìš©)\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # step 1: ì „ì²˜ë¦¬\n",
        "    ('svc', SVC())                 # step 2: ëª¨ë¸\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)     # ë‚´ë¶€ì ìœ¼ë¡œ:\n",
        "# scaler.fit(X_train) + scaler.transform(X_train)\n",
        "# svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "pipe.predict(X_test)           # ë‚´ë¶€ì ìœ¼ë¡œ:\n",
        "# scaler.transform(X_test) (trainì—ì„œ í•™ìŠµí•œ í‰ê· /ë¶„ì‚°ë§Œ ì‚¬ìš©)\n",
        "# svc.predict(X_test_scaled)\n",
        "```\n",
        "\n",
        "- `fit`ì„ í˜¸ì¶œí•˜ë©´ â†’ train ë°ì´í„°ì—ì„œë§Œ **ì „ì²˜ë¦¬ fit**  \n",
        "- `predict`ë¥¼ í˜¸ì¶œí•˜ë©´ â†’ trainì—ì„œ í•™ìŠµí•œ ê¸°ì¤€(í‰ê· /ë¶„ì‚°)ìœ¼ë¡œ test ë°ì´í„° ë³€í™˜ í›„ ì˜ˆì¸¡  \n",
        "- ë”°ë¼ì„œ **test ë°ì´í„°ëŠ” ì˜¤ì§ í‰ê°€ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©** â†’ ëˆ„ìˆ˜ ìë™ ë°©ì§€\n",
        "\n",
        "\n",
        "### âœ… ì™œ Pipelineì´ ì¤‘ìš”í•œê°€?\n",
        "- ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ ë”°ë¡œ ë‘ë©´, ì‚¬ìš©ìê°€ ì‹¤ìˆ˜ë¡œ `fit(X ì „ì²´)` ê°™ì€ ì½”ë“œë¥¼ ì§¤ ìˆ˜ ìˆìŒ â†’ ëˆ„ìˆ˜ ë°œìƒ  \n",
        "- **Pipelineì€ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ í•œ ë©ì–´ë¦¬ë¡œ ë¬¶ì–´ì„œ**,  \n",
        "  - í•™ìŠµ(train ë‹¨ê³„)ì—ì„œëŠ” train ë°ì´í„°ë¡œë§Œ ì „ì²˜ë¦¬ fit  \n",
        "  - ê²€ì¦/í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œëŠ” transformë§Œ ì ìš©  \n",
        "- ì¦‰, **ì‚¬ìš©ìê°€ ë”°ë¡œ êµ¬ë¶„í•´ì¤„ í•„ìš” ì—†ì´** ìë™ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë™ì‘  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "494be65c",
      "metadata": {},
      "source": [
        "### 3) GridSearchCV + Pipeline ì‚¬ìš©ë²•\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 1. Pipeline êµ¬ì„± (ìŠ¤í…ì— ì´ë¦„ ë¶€ì—¬)\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),   #  step 1 ì „ì²˜ë¦¬\n",
        "    ('svc', SVC())                  #  step 2 ëª¨ë¸\n",
        "])\n",
        "\n",
        "# 2. íƒìƒ‰í•  íŒŒë¼ë¯¸í„° (ìŠ¤í…ì´ë¦„__íŒŒë¼ë¯¸í„°)\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10], # 'svc' ìŠ¤í…ì˜ C íŒŒë¼ë¯¸í„°\n",
        "    'svc__kernel': ['linear', 'rbf'], # 'svc' ìŠ¤í…ì˜ kernel íŒŒë¼ë¯¸í„°\n",
        "    'svc__gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# 3. GridSearchCV ì‹¤í–‰\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy') # cv=5 : 5-fold êµì°¨ê²€ì¦\n",
        "grid.fit(*load_iris(return_X_y=True))\n",
        "\n",
        "print(\"ìµœì  íŒŒë¼ë¯¸í„°:\", grid.best_params_)\n",
        "print(\"ìµœì  ì„±ëŠ¥:\", grid.best_score_)\n",
        "```\n",
        "\n",
        "\n",
        "### 4) í•µì‹¬ ì •ë¦¬\n",
        "- **Pipeline**: ì „ì²˜ë¦¬ + ëª¨ë¸ì„ í•œ ë©ì–´ë¦¬ë¡œ ë¬¶ìŒ.  \n",
        "- **GridSearchCV**: í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì „ìˆ˜ì¡°ì‚¬í•´ ìµœì ê°’ ì„ íƒ.  \n",
        "- **ëˆ„ìˆ˜ ë°©ì§€**: ì „ì²˜ë¦¬ëŠ” foldë³„ trainì—ì„œë§Œ `fit`, valid/testëŠ” `transform`ë§Œ ì ìš©.  \n",
        "- **param_grid í‚¤**: `ìŠ¤í…ì´ë¦„__íŒŒë¼ë¯¸í„°` í˜•ì‹ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•¨.  \n",
        "\n",
        "\n",
        "### âœ… ìš”ì•½ ê·¸ë¦¼\n",
        "\n",
        "```\n",
        "[Raw Data] â†’ [Scaler (fit on train only)] â†’ [Model] â†’ [Predict]\n",
        "                â†‘\n",
        "                â””â”€ Pipelineì´ ìë™ìœ¼ë¡œ ëˆ„ìˆ˜ ë°©ì§€ ë³´ì¥\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee120190",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# ------------------------------------------\n",
        "# íŒŒì´í”„ë¼ì¸: [ìŠ¤ì¼€ì¼ë§ -> ë¡œì§€ìŠ¤í‹±íšŒê·€]\n",
        "# ------------------------------------------\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
        "#   - íŒŒì´í”„ë¼ì¸ ìŠ¤í… ì´ë¦„ 'clf__' ì ‘ë‘ì‚¬ë¡œ ì ‘ê·¼\n",
        "# ------------------------------------------\n",
        "param_grid = {\n",
        "    \"clf__C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \"clf__penalty\": [\"l2\"],            # liblinear/lbfgs ê¸°ì¤€\n",
        "    \"clf__solver\": [\"liblinear\", \"lbfgs\"]\n",
        "}\n",
        "\n",
        "# ------------------------------------------\n",
        "# êµì°¨ ê²€ì¦ ì„¤ì •(ê³„ì¸µí™” K-ê²¹)\n",
        "# ------------------------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ------------------------------------------\n",
        "# GridSearchCV: scoring ë³€ê²½ ê°€ëŠ¥(ë¶ˆê· í˜•ì‹œ f1_macro ë“± ê¶Œì¥)\n",
        "# ------------------------------------------\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", grid.best_params_)\n",
        "print(\"ê²€ì¦ í‰ê·  ì ìˆ˜(êµì°¨ê²€ì¦):\", grid.best_score_)\n",
        "\n",
        "# ------------------------------------------\n",
        "# ì„ íƒëœ ìµœì  ëª¨ë¸ë¡œ ê²€ì¦/í…ŒìŠ¤íŠ¸ í‰ê°€\n",
        "# ------------------------------------------\n",
        "best_model = grid.best_estimator_\n",
        "valid_pred = best_model.predict(X_valid)\n",
        "test_pred  = best_model.predict(X_test)\n",
        "\n",
        "print(\"VALID accuracy:\", accuracy_score(y_valid, valid_pred))\n",
        "print(\"TEST  accuracy:\", accuracy_score(y_test,  test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9f3c56a",
      "metadata": {},
      "source": [
        "> **ì™œ Pipelineì¸ê°€?**  \n",
        "> ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ train+valid ì „ì²´ì— ë¯¸ë¦¬ `fit`í•´ë²„ë¦¬ë©´ **ê²€ì¦ ì •ë³´ê°€ í›ˆë ¨ì— ìƒˆëŠ” ë°ì´í„° ëˆ„ìˆ˜** ë°œìƒ.  \n",
        "> Pipelineì€ ê° í´ë“œë§ˆë‹¤ **í›ˆë ¨ íŒŒíŠ¸ì—ë§Œ fit â†’ ê²€ì¦ íŒŒíŠ¸ì— transform**ì„ ìë™ ì ìš©í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb79fac",
      "metadata": {},
      "source": [
        "## 3.7 ì¤‘ì²© êµì°¨ ê²€ì¦(Nested CV): ê³¼ì í•©ëœ íŠœë‹ì„ ë°©ì§€í•œ **ê³µì •í•œ** ì„±ëŠ¥ ì¶”ì •\n",
        "- **ë°”ê¹¥(outer) CV**: ì¼ë°˜í™” ì„±ëŠ¥ ì¶”ì •\n",
        "- **ì•ˆìª½(inner) CV**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ(GridSearch)\n",
        "- ì¥ì : **íŠœë‹ í¸í–¥**ì„ ì¤„ì¸ â€œê³µì •í•œâ€ ìµœì¢… ì ìˆ˜ íšë“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5867a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "param_grid = {\"clf__C\": [0.01, 0.1, 1, 10, 100]}\n",
        "inner_search = GridSearchCV(pipe, param_grid, cv=inner_cv, scoring=\"f1_macro\", n_jobs=-1)\n",
        "\n",
        "# ë°”ê¹¥ìª½ì—ì„œ inner_search ìì²´ë¥¼ í‰ê°€(ê° í´ë“œë§ˆë‹¤ ì•ˆìª½ì—ì„œ íŠœë‹ ìˆ˜í–‰)\n",
        "nested_scores = cross_val_score(inner_search, X, y, cv=outer_cv, scoring=\"f1_macro\", n_jobs=-1)\n",
        "\n",
        "print(\"Nested CV f1_macro:\", nested_scores)\n",
        "print(\"Nested CV í‰ê· :\", nested_scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6368cee2",
      "metadata": {},
      "source": [
        "## 3.8 ì¶”ê°€ íŒ & í”í•œ í•¨ì •\n",
        "- **Seed ê³ ì •**: `random_state` ê³ ì • â†’ ì¬í˜„ ê°€ëŠ¥ì„±â†‘\n",
        "- **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: `stratify`, `class_weight='balanced'`, ì ì ˆ ì§€í‘œ(F1, PR-AUC) ì‚¬ìš©\n",
        "- **ë² ì´ìŠ¤ë¼ì¸**: ê°„ë‹¨ ëª¨ë¸(ë¡œì§€ìŠ¤í‹±/ë¦¬ë‹ˆì–´)ë¡œ ê¸°ì¤€ ì ìˆ˜ ë§Œë“  ë’¤ ë³µì¡ë„ ì¦ê°€\n",
        "- **RandomizedSearchCV**: í° ê³µê°„ì€ **ëœë¤ íƒìƒ‰**ì´ íš¨ìœ¨ì \n",
        "- **Bayesian Optimization**: ê³ ì„±ëŠ¥ íƒìƒ‰ ë„êµ¬(Optuna, skopt ë“±)ë„ ê³ ë ¤\n",
        "- **íŠ¹ì„± ìŠ¤ì¼€ì¼ë§**: ê±°ë¦¬/ì •ê·œí™” ê¸°ë°˜ ëª¨ë¸(SVM, KNN, ë¡œì§€ìŠ¤í‹± ë“±)ì—” í•„ìˆ˜\n",
        "- **ë°ì´í„° ëˆ„ìˆ˜**: í†µí•© ì „ì²˜ë¦¬(ìŠ¤ì¼€ì¼ë§/ì¸ì½”ë”©/ì„ íƒ)ëŠ” **ë°˜ë“œì‹œ Pipeline ì•ˆì—ì„œ**!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e42142f",
      "metadata": {},
      "source": [
        "## 3.9 ìš”ì•½ (Cheat Sheet)\n",
        "- **ë¶„í• **: 8:1:1(ë˜ëŠ” êµì°¨ ê²€ì¦), ì‹œê³„ì—´/ê·¸ë£¹ì€ ì „ìš© CV ì‚¬ìš©\n",
        "- **ì§€í‘œ**: ë¬¸ì œ íŠ¹ì„±ì— ë§ê²Œ ì„ íƒ(ë¶ˆê· í˜•ì€ F1Â·PR-AUC)\n",
        "- **íŠœë‹**: Pipeline + (Grid/Randomized)Search, ê²€ì¦ ë°ì´í„°ë¡œ ë¹„êµ\n",
        "- **ê²€ì¦ ê°•í™”**: Nested CVë¡œ ê³µì •í•œ ìµœì¢… ì„±ëŠ¥ ì¶”ì •\n",
        "- **ëˆ„ìˆ˜ ê¸ˆì§€**: ì „ì²˜ë¦¬ëŠ” í•­ìƒ í´ë“œ ë‚´ë¶€ì—ì„œ `fit`!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034d694f",
      "metadata": {},
      "source": [
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- [ ] 8:1:1 ë¶„í•  ë˜ëŠ” êµì°¨ ê²€ì¦ìœ¼ë¡œ **ì¼ë°˜í™” ì„±ëŠ¥**ì„ í™•ì¸í–ˆëŠ”ê°€?  \n",
        "- [ ] ì „ì²˜ë¦¬Â·ëª¨ë¸ì„ **Pipeline**ìœ¼ë¡œ ë¬¶ì–´ **ëˆ„ìˆ˜**ë¥¼ ë°©ì§€í–ˆëŠ”ê°€?  \n",
        "- [ ] ë¬¸ì œ íŠ¹ì„±ì— ë§ëŠ” **í‰ê°€ì§€í‘œ**ë¥¼ ì„ íƒí–ˆëŠ”ê°€?  \n",
        "- [ ] í•©ë¦¬ì ì¸ **í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„**ì„ ì •ì˜í–ˆëŠ”ê°€?  \n",
        "- [ ] (ì„ íƒ) **Nested CV**ë¡œ íŠœë‹ í¸í–¥ì„ ì¤„ì˜€ëŠ”ê°€?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b73e0f3c",
      "metadata": {},
      "source": [
        "## ë¨¸ì‹ ëŸ¬ë‹ ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ â€“ ì‹¤ìŠµ ë¬¸ì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d977f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "titanic = pd.read_csv(\"data/titanic.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "333b0249",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 1. Feature Scaling\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Age` ì»¬ëŸ¼ì„ ë¶ˆëŸ¬ì™€ì„œ **ì •ê·œí™”(Normalization)** ì™€ **í‘œì¤€í™”(Standardization)** ë¥¼ ì ìš©í•´ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "titanic = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "age = titanic[[\"Age\"]].dropna()# ê²°ì¸¡ì¹˜ ì œê±°\n",
        "\n",
        "# ì •ê·œí™”\n",
        "minmax = MinMaxScaler().fit_transform(age)\n",
        "print(\"ì •ê·œí™” ê²°ê³¼:\\n\", minmax[:5])\n",
        "\n",
        "# í‘œì¤€í™”\n",
        "standard = StandardScaler().fit_transform(age)\n",
        "print(\"í‘œì¤€í™” ê²°ê³¼:\\n\", standard[:5])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd0617f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e312907f",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 2. One-hot Encoding\n",
        "Titanic ë°ì´í„°ì…‹ì˜ `Sex` ì»¬ëŸ¼ì„ One-hot Encodingí•˜ì—¬ ìƒˆë¡œìš´ DataFrameì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "encoded = pd.get_dummies(titanic[[\"Sex\"]], prefix=\"Sex\")\n",
        "print(encoded.head())\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f372c3a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65918235",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 3. L1 / L2 ì •ê·œí™”\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Pclass`, `Age`, `Fare`ë¥¼ ì…ë ¥ ë³€ìˆ˜ë¡œ, `Survived`ë¥¼ íƒ€ê¹ƒ ë³€ìˆ˜ë¡œ í•˜ì—¬  \n",
        "Lasso(L1)ì™€ Ridge(L2) íšŒê·€ë¥¼ ê°ê° ì ìš©í•´ë³´ê³  ì„±ëŠ¥(ê²°ì •ê³„ìˆ˜)ì„ ë¹„êµí•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# ê°„ë‹¨í•œ ì „ì²˜ë¦¬\n",
        "df = titanic[[\"Survived\", \"Pclass\",  \"Survived\", \"Age\", \"Fare\"]].dropna()\n",
        "X = df[[\"Pclass\", \"Survived\", \"Fare\"]]\n",
        "y = df[\"Age\"]\n",
        "\n",
        "# ë°ì´í„° ë¶„í• \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ridge (L2)\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "print(\"Ridge score:\", ridge.score(X_test, y_test)) # .score : RÂ² (ê²°ì •ê³„ìˆ˜) \n",
        "\n",
        "# RÂ² = 1 â†’ ì™„ë²½í•˜ê²Œ ì˜ˆì¸¡\n",
        "# RÂ² = 0 â†’ í‰ê· ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ìˆ˜ì¤€\n",
        "# RÂ² < 0 â†’ ëª¨ë¸ì´ í‰ê· ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒë³´ë‹¤ ì˜¤íˆë ¤ ëª»í•¨\n",
        "\n",
        "# Lasso (L1)\n",
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X_train, y_train)\n",
        "print(\"Lasso score:\", lasso.score(X_test, y_test))\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e520f16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "943b8cee",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 4. kê²¹ êµì°¨ ê²€ì¦\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Pclass`, `Sex`, `Age`ë¥¼ ì‚¬ìš©í•´ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ í•™ìŠµí•˜ê³ , 5ê²¹ êµì°¨ ê²€ì¦ìœ¼ë¡œ í‰ê·  ì •í™•ë„ë¥¼ êµ¬í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# ê°„ë‹¨í•œ ì „ì²˜ë¦¬\n",
        "df = titanic[[\"Survived\", \"Pclass\", \"Sex\", \"Age\"]].dropna()\n",
        "df = pd.get_dummies(df, columns=[\"Sex\"])\n",
        "X = df.drop(\"Survived\", axis=1)\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "print(\"êµì°¨ ê²€ì¦ ì ìˆ˜:\", scores)\n",
        "print(\"í‰ê·  ì •í™•ë„:\", scores.mean())\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bab533",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a58a48",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 5. ê·¸ë¦¬ë“œ ì„œì¹˜\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , `C` ê°’ í›„ë³´ [0.01, 0.1, 1, 10]ì— ëŒ€í•´ GridSearchCVë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\"C\": [0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"ìµœì  íŒŒë¼ë¯¸í„°:\", grid.best_params_)\n",
        "print(\"ìµœì  ì„±ëŠ¥:\", grid.best_score_)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebf6c83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì—¬ê¸°ì— ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce670c1c",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 6. ë°ì´í„° ë¶„í•  (Train/Validation/Test)\n",
        "Titanic ë°ì´í„°ì…‹ì„ **8:1:1 ë¹„ìœ¨**ë¡œ í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = titanic[[\"Survived\", \"Pclass\", \"Age\", \"Fare\"]].dropna()\n",
        "X = df.drop(\"Survived\", axis=1)\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# 8:2 ë¶„í•  â†’ 0.2 ì¤‘ ì ˆë°˜ì€ ê²€ì¦, ì ˆë°˜ì€ í…ŒìŠ¤íŠ¸\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_valid.shape, X_test.shape)\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9081c2",
      "metadata": {},
      "source": [
        "\n",
        "### ë¬¸ì œ 7. í‘œì¤€í™” + ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Age`, `Fare`ë¥¼ ì…ë ¥ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ê³ , **í‘œì¤€í™”(StandardScaler)**ë¥¼ ì ìš©í•œ í›„ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ í•™ìŠµí•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "df = titanic[[\"Survived\", \"Age\", \"Fare\"]].dropna()\n",
        "X = df[[\"Age\", \"Fare\"]]\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "print(\"ëª¨ë¸ ì •í™•ë„:\", model.score(X_scaled, y))\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d488df",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 8. ROC-AUC í‰ê°€\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Pclass`, `Sex`, `Age`ë¥¼ ì‚¬ìš©í•´ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ í•™ìŠµí•˜ê³ , **ROC-AUC ì ìˆ˜**ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "df = titanic[[\"Survived\", \"Pclass\", \"Sex\", \"Age\"]].dropna()\n",
        "df = pd.get_dummies(df, columns=[\"Sex\"])\n",
        "X = df.drop(\"Survived\", axis=1)\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X, y)\n",
        "probs = model.predict_proba(X)[:, 1]\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y, probs))\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2415924f",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 9. êµì°¨ ê²€ì¦ ì§€í‘œ ë³€ê²½\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , **êµì°¨ ê²€ì¦ ì‹œ Accuracyê°€ ì•„ë‹Œ F1-score**ë¥¼ ì‚¬ìš©í•´ í‰ê·  ì„±ëŠ¥ì„ êµ¬í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "scores = cross_val_score(LogisticRegression(max_iter=200), X, y, cv=5, scoring=\"f1\")\n",
        "print(\"í‰ê·  F1-score:\", scores.mean())\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5870092",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 10. íŒŒì´í”„ë¼ì¸(Pipeline) í™œìš©\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Age`, `Fare`ë¥¼ ì…ë ¥ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬,  \n",
        "**[í‘œì¤€í™” â†’ ë¡œì§€ìŠ¤í‹± íšŒê·€]** ë‹¨ê³„ë¥¼ Pipelineìœ¼ë¡œ êµ¬ì„±í•˜ê³  ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "pipe.fit(X, y)\n",
        "print(\"ì •í™•ë„:\", pipe.score(X, y))\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8399a7a",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 11. Randomized Search\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ `C` ê°’ì„ [0.001, 0.01, 0.1, 1, 10, 100] ì¤‘ì—ì„œ,  \n",
        "**RandomizedSearchCV**ë¥¼ ì‚¬ìš©í•´ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "search = RandomizedSearchCV(LogisticRegression(max_iter=200), param_dist, cv=5, n_iter=3, random_state=42)\n",
        "search.fit(X, y)\n",
        "\n",
        "print(\"ìµœì  íŒŒë¼ë¯¸í„°:\", search.best_params_)\n",
        "print(\"ìµœì  ì ìˆ˜:\", search.best_score_)\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26fc612",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 12. íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸ (Lasso)\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ `Pclass`, `Age`, `Fare`ë¥¼ ì…ë ¥ ë³€ìˆ˜ë¡œ í•˜ê³ ,  \n",
        "Lasso(L1) íšŒê·€ë¥¼ í•™ìŠµí•œ í›„ **ê³„ìˆ˜(coefficient)** ê°’ì„ ì¶œë ¥í•´ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X, y)\n",
        "\n",
        "print(\"ê³„ìˆ˜:\", lasso.coef_)\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "933e4471",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 13. Confusion Matrix\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ ,  \n",
        "**í˜¼ë™ í–‰ë ¬(confusion matrix)**ì„ ì¶œë ¥í•´ë³´ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X, y)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "print(confusion_matrix(y, y_pred))\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47836a0",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 14. Classification Report\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ ,  \n",
        "**Precision, Recall, F1-score**ë¥¼ í¬í•¨í•œ Classification Reportë¥¼ ì¶œë ¥í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y, y_pred))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9be32f7",
      "metadata": {},
      "source": [
        "### ë¬¸ì œ 15. Nested Cross Validation\n",
        "Titanic ë°ì´í„°ì…‹ì—ì„œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ ,  \n",
        "ì•ˆìª½(inner) êµì°¨ ê²€ì¦ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•œ ë’¤,  \n",
        "ë°”ê¹¥ìª½(outer) êµì°¨ ê²€ì¦ìœ¼ë¡œ ìµœì¢… ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” **Nested CV**ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.  \n",
        "\n",
        "<details>\n",
        "<summary>ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
        "\n",
        "param_grid = {\"C\": [0.01, 0.1, 1, 10]}\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=inner_cv)\n",
        "nested_scores = cross_val_score(grid, X, y, cv=outer_cv)\n",
        "\n",
        "print(\"Nested CV ì ìˆ˜:\", nested_scores)\n",
        "print(\"í‰ê·  ì ìˆ˜:\", nested_scores.mean())\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c172adfd",
      "metadata": {},
      "source": [
        "### âœ… ì²´í¬í¬ì¸íŠ¸\n",
        "- ì „ì²˜ë¦¬(ìŠ¤ì¼€ì¼ë§, ì›-í•« ì¸ì½”ë”©)ëŠ” ëª¨ë¸ í•™ìŠµì— í•„ìˆ˜ì ì´ë‹¤.  \n",
        "- ì •ê·œí™”(L1, L2)ëŠ” ê³¼ì í•©ì„ ë°©ì§€í•˜ê³  ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì¸ë‹¤.  \n",
        "- kê²¹ êµì°¨ ê²€ì¦ì€ ëª¨ë¸ ì•ˆì •ì„±ì„ í‰ê°€í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì´ë‹¤.  \n",
        "- Grid SearchëŠ” ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì¤€ë‹¤.  "
      ]
    }
  ],
  "metadata": {
    "encoded_email": [
      "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ=="
    ],
    "filename": "MS0xMF/rqLjsi6Drn6zri51f642UX+u5oOultOqzoF/soJXtmZXtlZjqsowuaXB5bmI=",
    "inserted_date": [
      "2025-09-19"
    ],
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
